{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Data and ML modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading library and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import scipy.spatial\n",
    "import sklearn.preprocessing\n",
    "import datashader as ds\n",
    "import colorcet as cc\n",
    "from findpeaks import findpeaks\n",
    "import seaborn as sns\n",
    "import missingno\n",
    "from statsmodels.graphics.tsaplots import acf\n",
    "import kydlib\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import tkinter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# sys.path.append(os.path.join('..', '..'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import toolkit as tk\n",
    "# /home/ainbahar/dataproject/3W-research-project/toolkit\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Load Data\n",
    "real_instances, simulated_instances, drawn_instances = tk.get_all_labels_and_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SOURCE</th>\n",
       "      <th>REAL</th>\n",
       "      <th>SIMULATED</th>\n",
       "      <th>HAND-DRAWN</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTANCE LABEL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 - Normal Operation</th>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 - Abrupt Increase of BSW</th>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 - Spurious Closure of DHSV</th>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 - Severe Slugging</th>\n",
       "      <td>32</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 - Flow Instability</th>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 - Rapid Productivity Loss</th>\n",
       "      <td>11</td>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 - Quick Restriction in PCK</th>\n",
       "      <td>6</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 - Scaling in PCK</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 - Hydrate in Production Line</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>1019</td>\n",
       "      <td>939</td>\n",
       "      <td>20</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SOURCE                          REAL  SIMULATED  HAND-DRAWN  TOTAL\n",
       "INSTANCE LABEL                                                    \n",
       "0 - Normal Operation             594          0           0    594\n",
       "1 - Abrupt Increase of BSW         5        114          10    129\n",
       "2 - Spurious Closure of DHSV      22         16           0     38\n",
       "3 - Severe Slugging               32         74           0    106\n",
       "4 - Flow Instability             344          0           0    344\n",
       "5 - Rapid Productivity Loss       11        439           0    450\n",
       "6 - Quick Restriction in PCK       6        215           0    221\n",
       "7 - Scaling in PCK                 5          0          10     15\n",
       "8 - Hydrate in Production Line     0         81           0     81\n",
       "TOTAL                           1019        939          20   1978"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of Instance\n",
    "toi = tk.create_table_of_instances(real_instances, simulated_instances, drawn_instances)\n",
    "toi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input instance label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances set to: 7 - Scaling in PCK\n"
     ]
    }
   ],
   "source": [
    "# Prompt user to input the number of instances\n",
    "try:\n",
    "    instance_n = int(input(\"Enter the number of instances: \"))\n",
    "    print(f\"Number of instances set to: {toi.index[instance_n]}\")\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Please enter a valid integer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713634e+06</td>\n",
       "      <td>109.556000</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.811070</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713652e+06</td>\n",
       "      <td>109.556150</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.807995</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713669e+06</td>\n",
       "      <td>109.556300</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.804920</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713686e+06</td>\n",
       "      <td>109.556450</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.801842</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713704e+06</td>\n",
       "      <td>109.556620</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.798764</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 14:08:27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.722798e+06</td>\n",
       "      <td>109.494825</td>\n",
       "      <td>2.187673e+06</td>\n",
       "      <td>68.287542</td>\n",
       "      <td>8.490644e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 14:08:28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.722796e+06</td>\n",
       "      <td>109.494842</td>\n",
       "      <td>2.187677e+06</td>\n",
       "      <td>68.287542</td>\n",
       "      <td>8.490657e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 14:08:29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.722793e+06</td>\n",
       "      <td>109.494859</td>\n",
       "      <td>2.187680e+06</td>\n",
       "      <td>68.287542</td>\n",
       "      <td>8.490671e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 14:08:30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.722791e+06</td>\n",
       "      <td>109.494876</td>\n",
       "      <td>2.187683e+06</td>\n",
       "      <td>68.287542</td>\n",
       "      <td>8.490684e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 14:08:31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.722788e+06</td>\n",
       "      <td>109.494893</td>\n",
       "      <td>2.187685e+06</td>\n",
       "      <td>68.287542</td>\n",
       "      <td>8.490698e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42974 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     P-PDG         P-TPT       T-TPT     P-MON-CKP  T-JUS-CKP  \\\n",
       "timestamp                                                                       \n",
       "2018-06-11 02:12:18    0.0  8.713634e+06  109.556000  2.142981e+06  68.811070   \n",
       "2018-06-11 02:12:19    0.0  8.713652e+06  109.556150  2.142981e+06  68.807995   \n",
       "2018-06-11 02:12:20    0.0  8.713669e+06  109.556300  2.142981e+06  68.804920   \n",
       "2018-06-11 02:12:21    0.0  8.713686e+06  109.556450  2.142981e+06  68.801842   \n",
       "2018-06-11 02:12:22    0.0  8.713704e+06  109.556620  2.142981e+06  68.798764   \n",
       "...                    ...           ...         ...           ...        ...   \n",
       "2018-06-11 14:08:27    0.0  8.722798e+06  109.494825  2.187673e+06  68.287542   \n",
       "2018-06-11 14:08:28    0.0  8.722796e+06  109.494842  2.187677e+06  68.287542   \n",
       "2018-06-11 14:08:29    0.0  8.722793e+06  109.494859  2.187680e+06  68.287542   \n",
       "2018-06-11 14:08:30    0.0  8.722791e+06  109.494876  2.187683e+06  68.287542   \n",
       "2018-06-11 14:08:31    0.0  8.722788e+06  109.494893  2.187685e+06  68.287542   \n",
       "\n",
       "                       P-JUS-CKGL  QGL  class  \n",
       "timestamp                                      \n",
       "2018-06-11 02:12:18  7.960069e+06  0.0    0.0  \n",
       "2018-06-11 02:12:19  7.960069e+06  0.0    0.0  \n",
       "2018-06-11 02:12:20  7.960069e+06  0.0    0.0  \n",
       "2018-06-11 02:12:21  7.960069e+06  0.0    0.0  \n",
       "2018-06-11 02:12:22  7.960069e+06  0.0    0.0  \n",
       "...                           ...  ...    ...  \n",
       "2018-06-11 14:08:27  8.490644e+06  0.0    7.0  \n",
       "2018-06-11 14:08:28  8.490657e+06  0.0    7.0  \n",
       "2018-06-11 14:08:29  8.490671e+06  0.0    7.0  \n",
       "2018-06-11 14:08:30  8.490684e+06  0.0    7.0  \n",
       "2018-06-11 14:08:31  8.490698e+06  0.0    7.0  \n",
       "\n",
       "[42974 rows x 8 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'trainDataset/train_df_instance_{instance_n}.csv', index_col='timestamp', parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = df.columns.difference(['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_windowing(df, window_size=60, step_size=15):\n",
    "    windows = [df.iloc[i:i + window_size] for i in range(0, len(df), window_size)]\n",
    "    # Select every 'step_size' window\n",
    "    selected_windows = windows[::step_size]\n",
    "    \n",
    "     # Add window ID\n",
    "    for window_id, window in enumerate(windows, start=1):\n",
    "        window['id'] = window_id\n",
    "\n",
    "    # Combine the selected windows into a single DataFrame\n",
    "    result_df = pd.concat(selected_windows)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713634e+06</td>\n",
       "      <td>109.556000</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.811070</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713652e+06</td>\n",
       "      <td>109.556150</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.807995</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713669e+06</td>\n",
       "      <td>109.556300</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.804920</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713686e+06</td>\n",
       "      <td>109.556450</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.801842</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.713704e+06</td>\n",
       "      <td>109.556620</td>\n",
       "      <td>2.142981e+06</td>\n",
       "      <td>68.798764</td>\n",
       "      <td>7.960069e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.723662e+06</td>\n",
       "      <td>109.489778</td>\n",
       "      <td>2.190326e+06</td>\n",
       "      <td>68.274614</td>\n",
       "      <td>8.484217e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.723661e+06</td>\n",
       "      <td>109.489796</td>\n",
       "      <td>2.190323e+06</td>\n",
       "      <td>68.274666</td>\n",
       "      <td>8.484227e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.723660e+06</td>\n",
       "      <td>109.489814</td>\n",
       "      <td>2.190320e+06</td>\n",
       "      <td>68.274718</td>\n",
       "      <td>8.484236e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.723660e+06</td>\n",
       "      <td>109.489832</td>\n",
       "      <td>2.190317e+06</td>\n",
       "      <td>68.274770</td>\n",
       "      <td>8.484245e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.723659e+06</td>\n",
       "      <td>109.489851</td>\n",
       "      <td>2.190315e+06</td>\n",
       "      <td>68.274828</td>\n",
       "      <td>8.484254e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     P-PDG         P-TPT       T-TPT     P-MON-CKP  T-JUS-CKP  \\\n",
       "timestamp                                                                       \n",
       "2018-06-11 02:12:18    0.0  8.713634e+06  109.556000  2.142981e+06  68.811070   \n",
       "2018-06-11 02:12:19    0.0  8.713652e+06  109.556150  2.142981e+06  68.807995   \n",
       "2018-06-11 02:12:20    0.0  8.713669e+06  109.556300  2.142981e+06  68.804920   \n",
       "2018-06-11 02:12:21    0.0  8.713686e+06  109.556450  2.142981e+06  68.801842   \n",
       "2018-06-11 02:12:22    0.0  8.713704e+06  109.556620  2.142981e+06  68.798764   \n",
       "...                    ...           ...         ...           ...        ...   \n",
       "2018-06-11 13:58:13    0.0  8.723662e+06  109.489778  2.190326e+06  68.274614   \n",
       "2018-06-11 13:58:14    0.0  8.723661e+06  109.489796  2.190323e+06  68.274666   \n",
       "2018-06-11 13:58:15    0.0  8.723660e+06  109.489814  2.190320e+06  68.274718   \n",
       "2018-06-11 13:58:16    0.0  8.723660e+06  109.489832  2.190317e+06  68.274770   \n",
       "2018-06-11 13:58:17    0.0  8.723659e+06  109.489851  2.190315e+06  68.274828   \n",
       "\n",
       "                       P-JUS-CKGL  QGL  class   id  \n",
       "timestamp                                           \n",
       "2018-06-11 02:12:18  7.960069e+06  0.0    0.0    1  \n",
       "2018-06-11 02:12:19  7.960069e+06  0.0    0.0    1  \n",
       "2018-06-11 02:12:20  7.960069e+06  0.0    0.0    1  \n",
       "2018-06-11 02:12:21  7.960069e+06  0.0    0.0    1  \n",
       "2018-06-11 02:12:22  7.960069e+06  0.0    0.0    1  \n",
       "...                           ...  ...    ...  ...  \n",
       "2018-06-11 13:58:13  8.484217e+06  0.0    7.0  706  \n",
       "2018-06-11 13:58:14  8.484227e+06  0.0    7.0  706  \n",
       "2018-06-11 13:58:15  8.484236e+06  0.0    7.0  706  \n",
       "2018-06-11 13:58:16  8.484245e+06  0.0    7.0  706  \n",
       "2018-06-11 13:58:17  8.484254e+06  0.0    7.0  706  \n",
       "\n",
       "[2880 rows x 9 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df = time_windowing(df)\n",
    "resampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>QGL</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:18</th>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.361673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767983</td>\n",
       "      <td>2.257823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:19</th>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.355200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.754849</td>\n",
       "      <td>2.262924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:20</th>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.348728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741714</td>\n",
       "      <td>2.268026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:21</th>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.342347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728569</td>\n",
       "      <td>2.273128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 02:12:22</th>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.335930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715419</td>\n",
       "      <td>2.278909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:13</th>\n",
       "      <td>1.839905</td>\n",
       "      <td>2.161575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523448</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:14</th>\n",
       "      <td>1.839952</td>\n",
       "      <td>2.161394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523226</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:15</th>\n",
       "      <td>1.840000</td>\n",
       "      <td>2.161228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523004</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:16</th>\n",
       "      <td>1.840047</td>\n",
       "      <td>2.161078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.522780</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 13:58:17</th>\n",
       "      <td>1.840095</td>\n",
       "      <td>2.160944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.522531</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     P-JUS-CKGL  P-MON-CKP  P-PDG     P-TPT  QGL  T-JUS-CKP  \\\n",
       "timestamp                                                                     \n",
       "2018-06-11 02:12:18   -0.896085  -0.395597    0.0 -1.361673  0.0   0.767983   \n",
       "2018-06-11 02:12:19   -0.896085  -0.395597    0.0 -1.355200  0.0   0.754849   \n",
       "2018-06-11 02:12:20   -0.896085  -0.395597    0.0 -1.348728  0.0   0.741714   \n",
       "2018-06-11 02:12:21   -0.896085  -0.395597    0.0 -1.342347  0.0   0.728569   \n",
       "2018-06-11 02:12:22   -0.896085  -0.395597    0.0 -1.335930  0.0   0.715419   \n",
       "...                         ...        ...    ...       ...  ...        ...   \n",
       "2018-06-11 13:58:13    1.839905   2.161575    0.0  2.347225  0.0  -1.523448   \n",
       "2018-06-11 13:58:14    1.839952   2.161394    0.0  2.346996  0.0  -1.523226   \n",
       "2018-06-11 13:58:15    1.840000   2.161228    0.0  2.346749  0.0  -1.523004   \n",
       "2018-06-11 13:58:16    1.840047   2.161078    0.0  2.346484  0.0  -1.522780   \n",
       "2018-06-11 13:58:17    1.840095   2.160944    0.0  2.346201  0.0  -1.522531   \n",
       "\n",
       "                        T-TPT  class   id  \n",
       "timestamp                                  \n",
       "2018-06-11 02:12:18  2.257823    0.0    1  \n",
       "2018-06-11 02:12:19  2.262924    0.0    1  \n",
       "2018-06-11 02:12:20  2.268026    0.0    1  \n",
       "2018-06-11 02:12:21  2.273128    0.0    1  \n",
       "2018-06-11 02:12:22  2.278909    0.0    1  \n",
       "...                       ...    ...  ...  \n",
       "2018-06-11 13:58:13  0.005571    7.0  706  \n",
       "2018-06-11 13:58:14  0.006183    7.0  706  \n",
       "2018-06-11 13:58:15  0.006802    7.0  706  \n",
       "2018-06-11 13:58:16  0.007428    7.0  706  \n",
       "2018-06-11 13:58:17  0.008061    7.0  706  \n",
       "\n",
       "[2880 rows x 9 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_value = resampled_df[cols_to_check]\n",
    "target_values = resampled_df['class']\n",
    "window_id = resampled_df['id']\n",
    "\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "features_scaled = scaler.fit_transform(features_value)\n",
    "\n",
    "# Combine scaled features with the labels\n",
    "resampled_df_scaled = pd.DataFrame(features_scaled, index=features_value.index, columns=features_value.columns)\n",
    "resampled_df_scaled['class'] = target_values.values\n",
    "resampled_df_scaled['id'] = window_id.values\n",
    "\n",
    "resampled_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  16,  31,  46,  61,  76,  91, 106, 121, 136, 151, 166, 181,\n",
       "       196, 211, 226, 241, 256, 271, 286, 301, 316, 331, 346, 361, 376,\n",
       "       391, 406, 421, 436, 451, 466, 481, 496, 511, 526, 541, 556, 571,\n",
       "       586, 601, 616, 631, 646, 661, 676, 691, 706])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df_scaled['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df_scaled = resampled_df_scaled.reset_index()\n",
    "\n",
    "# Rename the 'timestamp' column to 'time'\n",
    "resampled_df_scaled.rename(columns={'timestamp': 'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>QGL</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-11 02:12:18</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.361673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767983</td>\n",
       "      <td>2.257823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-11 02:12:19</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.355200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.754849</td>\n",
       "      <td>2.262924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-11 02:12:20</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.348728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741714</td>\n",
       "      <td>2.268026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-11 02:12:21</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.342347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728569</td>\n",
       "      <td>2.273128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-11 02:12:22</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.335930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715419</td>\n",
       "      <td>2.278909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>2018-06-11 13:58:13</td>\n",
       "      <td>1.839905</td>\n",
       "      <td>2.161575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523448</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>2018-06-11 13:58:14</td>\n",
       "      <td>1.839952</td>\n",
       "      <td>2.161394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523226</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>2018-06-11 13:58:15</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>2.161228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523004</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>2018-06-11 13:58:16</td>\n",
       "      <td>1.840047</td>\n",
       "      <td>2.161078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.522780</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>2018-06-11 13:58:17</td>\n",
       "      <td>1.840095</td>\n",
       "      <td>2.160944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.522531</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  P-JUS-CKGL  P-MON-CKP  P-PDG     P-TPT  QGL  \\\n",
       "0    2018-06-11 02:12:18   -0.896085  -0.395597    0.0 -1.361673  0.0   \n",
       "1    2018-06-11 02:12:19   -0.896085  -0.395597    0.0 -1.355200  0.0   \n",
       "2    2018-06-11 02:12:20   -0.896085  -0.395597    0.0 -1.348728  0.0   \n",
       "3    2018-06-11 02:12:21   -0.896085  -0.395597    0.0 -1.342347  0.0   \n",
       "4    2018-06-11 02:12:22   -0.896085  -0.395597    0.0 -1.335930  0.0   \n",
       "...                  ...         ...        ...    ...       ...  ...   \n",
       "2875 2018-06-11 13:58:13    1.839905   2.161575    0.0  2.347225  0.0   \n",
       "2876 2018-06-11 13:58:14    1.839952   2.161394    0.0  2.346996  0.0   \n",
       "2877 2018-06-11 13:58:15    1.840000   2.161228    0.0  2.346749  0.0   \n",
       "2878 2018-06-11 13:58:16    1.840047   2.161078    0.0  2.346484  0.0   \n",
       "2879 2018-06-11 13:58:17    1.840095   2.160944    0.0  2.346201  0.0   \n",
       "\n",
       "      T-JUS-CKP     T-TPT  class   id  \n",
       "0      0.767983  2.257823    0.0    1  \n",
       "1      0.754849  2.262924    0.0    1  \n",
       "2      0.741714  2.268026    0.0    1  \n",
       "3      0.728569  2.273128    0.0    1  \n",
       "4      0.715419  2.278909    0.0    1  \n",
       "...         ...       ...    ...  ...  \n",
       "2875  -1.523448  0.005571    7.0  706  \n",
       "2876  -1.523226  0.006183    7.0  706  \n",
       "2877  -1.523004  0.006802    7.0  706  \n",
       "2878  -1.522780  0.007428    7.0  706  \n",
       "2879  -1.522531  0.008061    7.0  706  \n",
       "\n",
       "[2880 rows x 10 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "def extract_and_impute_features(data, id_column='id', timestamp_column='timestamp', drop_columns=['class'], custom_fc_parameters=None):\n",
    "    \n",
    "    if custom_fc_parameters is None:\n",
    "        custom_fc_parameters = {\n",
    "            'mean': None,\n",
    "            'median': None,\n",
    "            'standard_deviation': None,\n",
    "            'variance': None,\n",
    "            'maximum': None,\n",
    "            'minimum': None\n",
    "        }\n",
    "\n",
    "    # Rename the timestamp column\n",
    "    data = data.rename(columns={timestamp_column: 'time'})\n",
    "\n",
    "    # Extract features\n",
    "    extracted_features = extract_features(\n",
    "        data.drop(columns=drop_columns),\n",
    "        column_id=id_column,\n",
    "        column_sort='time',\n",
    "        default_fc_parameters=custom_fc_parameters\n",
    "    )\n",
    "\n",
    "    # Impute missing values\n",
    "    selected_features = impute(extracted_features)\n",
    "\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>QGL</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-11 02:12:18</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.361673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767983</td>\n",
       "      <td>2.257823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-11 02:12:19</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.355200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.754849</td>\n",
       "      <td>2.262924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-11 02:12:20</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.348728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741714</td>\n",
       "      <td>2.268026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-11 02:12:21</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.342347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728569</td>\n",
       "      <td>2.273128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-11 02:12:22</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.335930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715419</td>\n",
       "      <td>2.278909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>2018-06-11 13:58:13</td>\n",
       "      <td>1.839905</td>\n",
       "      <td>2.161575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523448</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>2018-06-11 13:58:14</td>\n",
       "      <td>1.839952</td>\n",
       "      <td>2.161394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523226</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>2018-06-11 13:58:15</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>2.161228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.523004</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>2018-06-11 13:58:16</td>\n",
       "      <td>1.840047</td>\n",
       "      <td>2.161078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.522780</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>2018-06-11 13:58:17</td>\n",
       "      <td>1.840095</td>\n",
       "      <td>2.160944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.522531</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>7.0</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  P-JUS-CKGL  P-MON-CKP  P-PDG     P-TPT  QGL  \\\n",
       "0    2018-06-11 02:12:18   -0.896085  -0.395597    0.0 -1.361673  0.0   \n",
       "1    2018-06-11 02:12:19   -0.896085  -0.395597    0.0 -1.355200  0.0   \n",
       "2    2018-06-11 02:12:20   -0.896085  -0.395597    0.0 -1.348728  0.0   \n",
       "3    2018-06-11 02:12:21   -0.896085  -0.395597    0.0 -1.342347  0.0   \n",
       "4    2018-06-11 02:12:22   -0.896085  -0.395597    0.0 -1.335930  0.0   \n",
       "...                  ...         ...        ...    ...       ...  ...   \n",
       "2875 2018-06-11 13:58:13    1.839905   2.161575    0.0  2.347225  0.0   \n",
       "2876 2018-06-11 13:58:14    1.839952   2.161394    0.0  2.346996  0.0   \n",
       "2877 2018-06-11 13:58:15    1.840000   2.161228    0.0  2.346749  0.0   \n",
       "2878 2018-06-11 13:58:16    1.840047   2.161078    0.0  2.346484  0.0   \n",
       "2879 2018-06-11 13:58:17    1.840095   2.160944    0.0  2.346201  0.0   \n",
       "\n",
       "      T-JUS-CKP     T-TPT  class   id  \n",
       "0      0.767983  2.257823    0.0    1  \n",
       "1      0.754849  2.262924    0.0    1  \n",
       "2      0.741714  2.268026    0.0    1  \n",
       "3      0.728569  2.273128    0.0    1  \n",
       "4      0.715419  2.278909    0.0    1  \n",
       "...         ...       ...    ...  ...  \n",
       "2875  -1.523448  0.005571    7.0  706  \n",
       "2876  -1.523226  0.006183    7.0  706  \n",
       "2877  -1.523004  0.006802    7.0  706  \n",
       "2878  -1.522780  0.007428    7.0  706  \n",
       "2879  -1.522531  0.008061    7.0  706  \n",
       "\n",
       "[2880 rows x 10 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [00:00<00:00, 263.61it/s]\n"
     ]
    }
   ],
   "source": [
    "y = resampled_df_scaled.groupby('id')['class'].first()\n",
    "X = extract_and_impute_features(resampled_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    P-JUS-CKGL__mean  P-JUS-CKGL__median  P-JUS-CKGL__standard_deviation  \\\n",
      "1          -0.896085           -0.896085                    1.110223e-16   \n",
      "16         -0.885541           -0.885543                    4.143325e-04   \n",
      "31         -0.868763           -0.868768                    4.445877e-04   \n",
      "46         -0.836679           -0.836674                    5.562732e-04   \n",
      "61         -0.801743           -0.801716                    1.205338e-03   \n",
      "\n",
      "    P-JUS-CKGL__variance  P-JUS-CKGL__maximum  P-JUS-CKGL__minimum  \\\n",
      "1           1.232595e-32            -0.896085            -0.896085   \n",
      "16          1.716714e-07            -0.884834            -0.886245   \n",
      "31          1.976582e-07            -0.867995            -0.869513   \n",
      "46          3.094399e-07            -0.835740            -0.837635   \n",
      "61          1.452840e-06            -0.799741            -0.803843   \n",
      "\n",
      "    P-MON-CKP__mean  P-MON-CKP__median  P-MON-CKP__standard_deviation  \\\n",
      "1         -0.408539          -0.395597                       0.021751   \n",
      "16        -0.855952          -0.857024                       0.006558   \n",
      "31        -0.709083          -0.710023                       0.002611   \n",
      "46        -0.521733          -0.520007                       0.003964   \n",
      "61        -0.558425          -0.559009                       0.004024   \n",
      "\n",
      "    P-MON-CKP__variance  ...  T-JUS-CKP__standard_deviation  \\\n",
      "1              0.000473  ...                       0.174616   \n",
      "16             0.000043  ...                       0.001802   \n",
      "31             0.000007  ...                       0.019537   \n",
      "46             0.000016  ...                       0.016880   \n",
      "61             0.000016  ...                       0.007407   \n",
      "\n",
      "    T-JUS-CKP__variance  T-JUS-CKP__maximum  T-JUS-CKP__minimum  T-TPT__mean  \\\n",
      "1              0.030491            0.767983            0.238172     2.186833   \n",
      "16             0.000003            0.273917            0.266663     2.610011   \n",
      "31             0.000382            0.721989            0.658324     2.306829   \n",
      "46             0.000285            1.494487            1.434600     1.812628   \n",
      "61             0.000055            1.902829            1.877594     1.830739   \n",
      "\n",
      "    T-TPT__median  T-TPT__standard_deviation  T-TPT__variance  T-TPT__maximum  \\\n",
      "1        2.229633                   0.121185         0.014686        2.327431   \n",
      "16       2.607677                   0.006759         0.000046        2.624352   \n",
      "31       2.304432                   0.005371         0.000029        2.318819   \n",
      "46       1.813480                   0.004221         0.000018        1.819434   \n",
      "61       1.830503                   0.005360         0.000029        1.839244   \n",
      "\n",
      "    T-TPT__minimum  \n",
      "1         1.965559  \n",
      "16        2.601740  \n",
      "31        2.301961  \n",
      "46        1.804589  \n",
      "61        1.821407  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "id\n",
      "1     0.0\n",
      "16    0.0\n",
      "31    0.0\n",
      "46    0.0\n",
      "61    0.0\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-JUS-CKGL__mean</th>\n",
       "      <th>P-JUS-CKGL__median</th>\n",
       "      <th>P-JUS-CKGL__standard_deviation</th>\n",
       "      <th>P-JUS-CKGL__variance</th>\n",
       "      <th>P-JUS-CKGL__maximum</th>\n",
       "      <th>P-JUS-CKGL__minimum</th>\n",
       "      <th>P-MON-CKP__mean</th>\n",
       "      <th>P-MON-CKP__median</th>\n",
       "      <th>P-MON-CKP__standard_deviation</th>\n",
       "      <th>P-MON-CKP__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>T-JUS-CKP__variance</th>\n",
       "      <th>T-JUS-CKP__maximum</th>\n",
       "      <th>T-JUS-CKP__minimum</th>\n",
       "      <th>T-TPT__mean</th>\n",
       "      <th>T-TPT__median</th>\n",
       "      <th>T-TPT__standard_deviation</th>\n",
       "      <th>T-TPT__variance</th>\n",
       "      <th>T-TPT__maximum</th>\n",
       "      <th>T-TPT__minimum</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>1.232595e-32</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.896085</td>\n",
       "      <td>-0.408539</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>0.021751</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>...</td>\n",
       "      <td>3.049081e-02</td>\n",
       "      <td>0.767983</td>\n",
       "      <td>0.238172</td>\n",
       "      <td>2.186833</td>\n",
       "      <td>2.229633</td>\n",
       "      <td>0.121185</td>\n",
       "      <td>0.014686</td>\n",
       "      <td>2.327431</td>\n",
       "      <td>1.965559</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.885541</td>\n",
       "      <td>-0.885543</td>\n",
       "      <td>4.143325e-04</td>\n",
       "      <td>1.716714e-07</td>\n",
       "      <td>-0.884834</td>\n",
       "      <td>-0.886245</td>\n",
       "      <td>-0.855952</td>\n",
       "      <td>-0.857024</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>3.247339e-06</td>\n",
       "      <td>0.273917</td>\n",
       "      <td>0.266663</td>\n",
       "      <td>2.610011</td>\n",
       "      <td>2.607677</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>2.624352</td>\n",
       "      <td>2.601740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.868763</td>\n",
       "      <td>-0.868768</td>\n",
       "      <td>4.445877e-04</td>\n",
       "      <td>1.976582e-07</td>\n",
       "      <td>-0.867995</td>\n",
       "      <td>-0.869513</td>\n",
       "      <td>-0.709083</td>\n",
       "      <td>-0.710023</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>3.817121e-04</td>\n",
       "      <td>0.721989</td>\n",
       "      <td>0.658324</td>\n",
       "      <td>2.306829</td>\n",
       "      <td>2.304432</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.318819</td>\n",
       "      <td>2.301961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.836679</td>\n",
       "      <td>-0.836674</td>\n",
       "      <td>5.562732e-04</td>\n",
       "      <td>3.094399e-07</td>\n",
       "      <td>-0.835740</td>\n",
       "      <td>-0.837635</td>\n",
       "      <td>-0.521733</td>\n",
       "      <td>-0.520007</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>2.849335e-04</td>\n",
       "      <td>1.494487</td>\n",
       "      <td>1.434600</td>\n",
       "      <td>1.812628</td>\n",
       "      <td>1.813480</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.819434</td>\n",
       "      <td>1.804589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.801743</td>\n",
       "      <td>-0.801716</td>\n",
       "      <td>1.205338e-03</td>\n",
       "      <td>1.452840e-06</td>\n",
       "      <td>-0.799741</td>\n",
       "      <td>-0.803843</td>\n",
       "      <td>-0.558425</td>\n",
       "      <td>-0.559009</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>5.486716e-05</td>\n",
       "      <td>1.902829</td>\n",
       "      <td>1.877594</td>\n",
       "      <td>1.830739</td>\n",
       "      <td>1.830503</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.839244</td>\n",
       "      <td>1.821407</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.765230</td>\n",
       "      <td>-0.765237</td>\n",
       "      <td>7.603757e-04</td>\n",
       "      <td>5.781712e-07</td>\n",
       "      <td>-0.763923</td>\n",
       "      <td>-0.766513</td>\n",
       "      <td>-0.423002</td>\n",
       "      <td>-0.423446</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>3.971649e-05</td>\n",
       "      <td>1.618730</td>\n",
       "      <td>1.596020</td>\n",
       "      <td>1.937297</td>\n",
       "      <td>1.936576</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>1.951509</td>\n",
       "      <td>1.925094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-0.746186</td>\n",
       "      <td>-0.746187</td>\n",
       "      <td>5.716091e-06</td>\n",
       "      <td>3.267369e-11</td>\n",
       "      <td>-0.746174</td>\n",
       "      <td>-0.746193</td>\n",
       "      <td>-0.493687</td>\n",
       "      <td>-0.487595</td>\n",
       "      <td>0.010399</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>...</td>\n",
       "      <td>2.112374e-06</td>\n",
       "      <td>1.368050</td>\n",
       "      <td>1.363227</td>\n",
       "      <td>1.220057</td>\n",
       "      <td>1.219773</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1.246684</td>\n",
       "      <td>1.195443</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.758909</td>\n",
       "      <td>-0.758903</td>\n",
       "      <td>7.603757e-04</td>\n",
       "      <td>5.781712e-07</td>\n",
       "      <td>-0.757626</td>\n",
       "      <td>-0.760216</td>\n",
       "      <td>-0.910650</td>\n",
       "      <td>-0.910537</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597691e-04</td>\n",
       "      <td>1.836049</td>\n",
       "      <td>1.794148</td>\n",
       "      <td>0.627857</td>\n",
       "      <td>0.628625</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.637082</td>\n",
       "      <td>0.615918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.797280</td>\n",
       "      <td>-0.797303</td>\n",
       "      <td>1.201091e-03</td>\n",
       "      <td>1.442619e-06</td>\n",
       "      <td>-0.795198</td>\n",
       "      <td>-0.799284</td>\n",
       "      <td>-1.055357</td>\n",
       "      <td>-1.055936</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>3.309602e-07</td>\n",
       "      <td>2.089596</td>\n",
       "      <td>2.087472</td>\n",
       "      <td>0.790488</td>\n",
       "      <td>0.793082</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.794868</td>\n",
       "      <td>0.779080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-0.829212</td>\n",
       "      <td>-0.829215</td>\n",
       "      <td>1.834467e-04</td>\n",
       "      <td>3.365270e-08</td>\n",
       "      <td>-0.828895</td>\n",
       "      <td>-0.829520</td>\n",
       "      <td>-1.150281</td>\n",
       "      <td>-1.149910</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.276392e-04</td>\n",
       "      <td>1.787406</td>\n",
       "      <td>1.748915</td>\n",
       "      <td>0.762861</td>\n",
       "      <td>0.762410</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.769842</td>\n",
       "      <td>0.756557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.835533</td>\n",
       "      <td>-0.835535</td>\n",
       "      <td>3.466206e-04</td>\n",
       "      <td>1.201459e-07</td>\n",
       "      <td>-0.834934</td>\n",
       "      <td>-0.836120</td>\n",
       "      <td>-1.077207</td>\n",
       "      <td>-1.076342</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>2.151957e-06</td>\n",
       "      <td>1.280243</td>\n",
       "      <td>1.275180</td>\n",
       "      <td>0.740999</td>\n",
       "      <td>0.739469</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.755097</td>\n",
       "      <td>0.732013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.851983</td>\n",
       "      <td>-0.851944</td>\n",
       "      <td>5.955725e-04</td>\n",
       "      <td>3.547066e-07</td>\n",
       "      <td>-0.851043</td>\n",
       "      <td>-0.853069</td>\n",
       "      <td>-1.086723</td>\n",
       "      <td>-1.088956</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>4.149155e-05</td>\n",
       "      <td>0.837235</td>\n",
       "      <td>0.816426</td>\n",
       "      <td>0.739752</td>\n",
       "      <td>0.739483</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.748663</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-0.893347</td>\n",
       "      <td>-0.893315</td>\n",
       "      <td>4.664509e-04</td>\n",
       "      <td>2.175765e-07</td>\n",
       "      <td>-0.892615</td>\n",
       "      <td>-0.894195</td>\n",
       "      <td>-1.102501</td>\n",
       "      <td>-1.099582</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303727e-04</td>\n",
       "      <td>0.701847</td>\n",
       "      <td>0.666193</td>\n",
       "      <td>0.226614</td>\n",
       "      <td>0.227037</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.241934</td>\n",
       "      <td>0.210301</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.937856</td>\n",
       "      <td>-0.937892</td>\n",
       "      <td>9.663119e-04</td>\n",
       "      <td>9.337587e-07</td>\n",
       "      <td>-0.936142</td>\n",
       "      <td>-0.939432</td>\n",
       "      <td>-0.837143</td>\n",
       "      <td>-0.834964</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>5.828250e-05</td>\n",
       "      <td>0.630651</td>\n",
       "      <td>0.604648</td>\n",
       "      <td>-0.634607</td>\n",
       "      <td>-0.632705</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-0.616396</td>\n",
       "      <td>-0.659814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.981027</td>\n",
       "      <td>-0.981055</td>\n",
       "      <td>9.391328e-04</td>\n",
       "      <td>8.819705e-07</td>\n",
       "      <td>-0.979375</td>\n",
       "      <td>-0.982579</td>\n",
       "      <td>-0.772451</td>\n",
       "      <td>-0.775370</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>4.071327e-05</td>\n",
       "      <td>0.053466</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>-1.375509</td>\n",
       "      <td>-1.375390</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>-1.358906</td>\n",
       "      <td>-1.393686</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>-1.018379</td>\n",
       "      <td>-1.018377</td>\n",
       "      <td>5.307954e-04</td>\n",
       "      <td>2.817437e-07</td>\n",
       "      <td>-1.017479</td>\n",
       "      <td>-1.019288</td>\n",
       "      <td>-0.915784</td>\n",
       "      <td>-0.916282</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635530e-05</td>\n",
       "      <td>-0.247815</td>\n",
       "      <td>-0.263782</td>\n",
       "      <td>-1.464603</td>\n",
       "      <td>-1.465015</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-1.459621</td>\n",
       "      <td>-1.468815</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-1.044323</td>\n",
       "      <td>-1.044321</td>\n",
       "      <td>3.421960e-04</td>\n",
       "      <td>1.170981e-07</td>\n",
       "      <td>-1.043745</td>\n",
       "      <td>-1.044910</td>\n",
       "      <td>-1.062139</td>\n",
       "      <td>-1.061006</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>2.465352e-05</td>\n",
       "      <td>-0.202698</td>\n",
       "      <td>-0.219851</td>\n",
       "      <td>-0.999022</td>\n",
       "      <td>-0.999514</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.985550</td>\n",
       "      <td>-1.010521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-1.065768</td>\n",
       "      <td>-1.065767</td>\n",
       "      <td>4.366846e-04</td>\n",
       "      <td>1.906935e-07</td>\n",
       "      <td>-1.065026</td>\n",
       "      <td>-1.066514</td>\n",
       "      <td>-1.131287</td>\n",
       "      <td>-1.131107</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>3.761583e-06</td>\n",
       "      <td>-0.295640</td>\n",
       "      <td>-0.301745</td>\n",
       "      <td>-0.650649</td>\n",
       "      <td>-0.650850</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.633616</td>\n",
       "      <td>-0.667374</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-1.089416</td>\n",
       "      <td>-1.089376</td>\n",
       "      <td>1.581517e-04</td>\n",
       "      <td>2.501195e-08</td>\n",
       "      <td>-1.089231</td>\n",
       "      <td>-1.089755</td>\n",
       "      <td>-0.999753</td>\n",
       "      <td>-0.998929</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262321e-06</td>\n",
       "      <td>-0.018979</td>\n",
       "      <td>-0.022792</td>\n",
       "      <td>-0.397007</td>\n",
       "      <td>-0.398081</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.386172</td>\n",
       "      <td>-0.404672</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-1.071482</td>\n",
       "      <td>-1.071485</td>\n",
       "      <td>5.315125e-04</td>\n",
       "      <td>2.825056e-07</td>\n",
       "      <td>-1.070570</td>\n",
       "      <td>-1.072381</td>\n",
       "      <td>-0.845140</td>\n",
       "      <td>-0.846769</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328838e-05</td>\n",
       "      <td>0.289282</td>\n",
       "      <td>0.278025</td>\n",
       "      <td>-0.063052</td>\n",
       "      <td>-0.063597</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.059616</td>\n",
       "      <td>-0.064312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-1.012325</td>\n",
       "      <td>-1.012367</td>\n",
       "      <td>1.496597e-03</td>\n",
       "      <td>2.239802e-06</td>\n",
       "      <td>-1.009695</td>\n",
       "      <td>-1.014791</td>\n",
       "      <td>-0.702382</td>\n",
       "      <td>-0.703707</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.937870e-04</td>\n",
       "      <td>-0.102637</td>\n",
       "      <td>-0.149570</td>\n",
       "      <td>-0.118322</td>\n",
       "      <td>-0.117261</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.109211</td>\n",
       "      <td>-0.130364</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>-0.913340</td>\n",
       "      <td>-0.913340</td>\n",
       "      <td>2.615726e-03</td>\n",
       "      <td>6.842024e-06</td>\n",
       "      <td>-0.908885</td>\n",
       "      <td>-0.917796</td>\n",
       "      <td>-0.434518</td>\n",
       "      <td>-0.432359</td>\n",
       "      <td>0.008720</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>...</td>\n",
       "      <td>4.793619e-05</td>\n",
       "      <td>-0.428964</td>\n",
       "      <td>-0.450813</td>\n",
       "      <td>-0.810568</td>\n",
       "      <td>-0.810573</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.782074</td>\n",
       "      <td>-0.839371</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.769518</td>\n",
       "      <td>-0.769541</td>\n",
       "      <td>2.681835e-03</td>\n",
       "      <td>7.192241e-06</td>\n",
       "      <td>-0.764907</td>\n",
       "      <td>-0.774043</td>\n",
       "      <td>-0.015984</td>\n",
       "      <td>-0.014808</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>...</td>\n",
       "      <td>4.439177e-04</td>\n",
       "      <td>0.227317</td>\n",
       "      <td>0.155983</td>\n",
       "      <td>-1.304925</td>\n",
       "      <td>-1.305326</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-1.290411</td>\n",
       "      <td>-1.317910</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.608848</td>\n",
       "      <td>-0.608877</td>\n",
       "      <td>3.124832e-03</td>\n",
       "      <td>9.764577e-06</td>\n",
       "      <td>-0.603472</td>\n",
       "      <td>-0.614121</td>\n",
       "      <td>0.190968</td>\n",
       "      <td>0.191222</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>3.897524e-06</td>\n",
       "      <td>0.781957</td>\n",
       "      <td>0.774528</td>\n",
       "      <td>-1.127066</td>\n",
       "      <td>-1.126516</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-1.110858</td>\n",
       "      <td>-1.144902</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-0.424740</td>\n",
       "      <td>-0.424736</td>\n",
       "      <td>3.511812e-03</td>\n",
       "      <td>1.233283e-05</td>\n",
       "      <td>-0.418765</td>\n",
       "      <td>-0.430729</td>\n",
       "      <td>0.030866</td>\n",
       "      <td>0.033963</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>6.685696e-07</td>\n",
       "      <td>0.743225</td>\n",
       "      <td>0.740496</td>\n",
       "      <td>-1.043801</td>\n",
       "      <td>-1.043648</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-1.038752</td>\n",
       "      <td>-1.049401</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>-0.239197</td>\n",
       "      <td>-0.239157</td>\n",
       "      <td>3.704126e-03</td>\n",
       "      <td>1.372055e-05</td>\n",
       "      <td>-0.232977</td>\n",
       "      <td>-0.245356</td>\n",
       "      <td>-0.020182</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>2.834618e-04</td>\n",
       "      <td>0.385279</td>\n",
       "      <td>0.331081</td>\n",
       "      <td>-1.091977</td>\n",
       "      <td>-1.091512</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-1.078731</td>\n",
       "      <td>-1.107039</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>-0.058151</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>3.397337e-03</td>\n",
       "      <td>1.154190e-05</td>\n",
       "      <td>-0.052400</td>\n",
       "      <td>-0.063974</td>\n",
       "      <td>-0.153477</td>\n",
       "      <td>-0.153516</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015864e-04</td>\n",
       "      <td>-0.023156</td>\n",
       "      <td>-0.057507</td>\n",
       "      <td>-0.728332</td>\n",
       "      <td>-0.729156</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.708725</td>\n",
       "      <td>-0.745165</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>2.871520e-03</td>\n",
       "      <td>8.245627e-06</td>\n",
       "      <td>0.112301</td>\n",
       "      <td>0.102285</td>\n",
       "      <td>-0.332198</td>\n",
       "      <td>-0.333275</td>\n",
       "      <td>0.010678</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>...</td>\n",
       "      <td>2.631931e-06</td>\n",
       "      <td>-0.426951</td>\n",
       "      <td>-0.433128</td>\n",
       "      <td>-0.208204</td>\n",
       "      <td>-0.208703</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.200212</td>\n",
       "      <td>-0.214436</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.243088</td>\n",
       "      <td>0.243078</td>\n",
       "      <td>2.487305e-03</td>\n",
       "      <td>6.186684e-06</td>\n",
       "      <td>0.247346</td>\n",
       "      <td>0.238872</td>\n",
       "      <td>-0.362195</td>\n",
       "      <td>-0.362015</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>4.116301e-05</td>\n",
       "      <td>-0.745610</td>\n",
       "      <td>-0.767449</td>\n",
       "      <td>-0.322088</td>\n",
       "      <td>-0.322077</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.311542</td>\n",
       "      <td>-0.332753</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.357812</td>\n",
       "      <td>0.357807</td>\n",
       "      <td>2.097821e-03</td>\n",
       "      <td>4.400855e-06</td>\n",
       "      <td>0.361553</td>\n",
       "      <td>0.354245</td>\n",
       "      <td>-0.267283</td>\n",
       "      <td>-0.267474</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>8.132204e-05</td>\n",
       "      <td>-0.449085</td>\n",
       "      <td>-0.479782</td>\n",
       "      <td>-0.680501</td>\n",
       "      <td>-0.681042</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.674406</td>\n",
       "      <td>-0.683935</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.467897</td>\n",
       "      <td>0.467908</td>\n",
       "      <td>2.308165e-03</td>\n",
       "      <td>5.327625e-06</td>\n",
       "      <td>0.471808</td>\n",
       "      <td>0.463945</td>\n",
       "      <td>0.054919</td>\n",
       "      <td>0.058752</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>...</td>\n",
       "      <td>2.247334e-05</td>\n",
       "      <td>-0.129309</td>\n",
       "      <td>-0.145459</td>\n",
       "      <td>-0.664913</td>\n",
       "      <td>-0.663788</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.659638</td>\n",
       "      <td>-0.674788</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.570375</td>\n",
       "      <td>0.570382</td>\n",
       "      <td>1.705359e-03</td>\n",
       "      <td>2.908251e-06</td>\n",
       "      <td>0.573100</td>\n",
       "      <td>0.567464</td>\n",
       "      <td>0.246168</td>\n",
       "      <td>0.243163</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>...</td>\n",
       "      <td>1.881468e-05</td>\n",
       "      <td>-0.436661</td>\n",
       "      <td>-0.450388</td>\n",
       "      <td>-0.485267</td>\n",
       "      <td>-0.485797</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.476882</td>\n",
       "      <td>-0.492520</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.658499</td>\n",
       "      <td>0.658499</td>\n",
       "      <td>1.307863e-03</td>\n",
       "      <td>1.710506e-06</td>\n",
       "      <td>0.660727</td>\n",
       "      <td>0.656272</td>\n",
       "      <td>0.155922</td>\n",
       "      <td>0.153727</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>6.101201e-05</td>\n",
       "      <td>-0.575593</td>\n",
       "      <td>-0.602210</td>\n",
       "      <td>-0.180291</td>\n",
       "      <td>-0.180210</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.172766</td>\n",
       "      <td>-0.187264</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.733684</td>\n",
       "      <td>0.733685</td>\n",
       "      <td>1.601146e-03</td>\n",
       "      <td>2.563668e-06</td>\n",
       "      <td>0.736417</td>\n",
       "      <td>0.730952</td>\n",
       "      <td>0.122556</td>\n",
       "      <td>0.123396</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.491621e-04</td>\n",
       "      <td>-0.729702</td>\n",
       "      <td>-0.768214</td>\n",
       "      <td>-0.062947</td>\n",
       "      <td>-0.061236</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.059830</td>\n",
       "      <td>-0.070435</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.815210</td>\n",
       "      <td>0.815179</td>\n",
       "      <td>2.054365e-03</td>\n",
       "      <td>4.220414e-06</td>\n",
       "      <td>0.818768</td>\n",
       "      <td>0.811770</td>\n",
       "      <td>0.154691</td>\n",
       "      <td>0.155149</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>3.076763e-06</td>\n",
       "      <td>-0.871302</td>\n",
       "      <td>-0.877115</td>\n",
       "      <td>-0.187390</td>\n",
       "      <td>-0.189870</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.175071</td>\n",
       "      <td>-0.192926</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.926897</td>\n",
       "      <td>0.926902</td>\n",
       "      <td>2.329813e-03</td>\n",
       "      <td>5.428027e-06</td>\n",
       "      <td>0.930854</td>\n",
       "      <td>0.922926</td>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.076908</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>3.420847e-05</td>\n",
       "      <td>-0.809170</td>\n",
       "      <td>-0.826575</td>\n",
       "      <td>-0.124756</td>\n",
       "      <td>-0.126518</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.115794</td>\n",
       "      <td>-0.128951</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1.030682</td>\n",
       "      <td>1.030702</td>\n",
       "      <td>1.702092e-03</td>\n",
       "      <td>2.897117e-06</td>\n",
       "      <td>1.033543</td>\n",
       "      <td>1.027745</td>\n",
       "      <td>0.277770</td>\n",
       "      <td>0.277653</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>7.895604e-05</td>\n",
       "      <td>-0.522345</td>\n",
       "      <td>-0.552698</td>\n",
       "      <td>-0.014022</td>\n",
       "      <td>-0.012465</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.011140</td>\n",
       "      <td>-0.022906</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1.106428</td>\n",
       "      <td>1.106427</td>\n",
       "      <td>9.076284e-04</td>\n",
       "      <td>8.237892e-07</td>\n",
       "      <td>1.107978</td>\n",
       "      <td>1.104877</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.020132</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>...</td>\n",
       "      <td>3.992722e-05</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>-0.150794</td>\n",
       "      <td>-0.150328</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.149181</td>\n",
       "      <td>-0.154897</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1.156549</td>\n",
       "      <td>1.156552</td>\n",
       "      <td>7.791263e-04</td>\n",
       "      <td>6.070377e-07</td>\n",
       "      <td>1.157872</td>\n",
       "      <td>1.155218</td>\n",
       "      <td>1.352103</td>\n",
       "      <td>1.355183</td>\n",
       "      <td>0.016452</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>...</td>\n",
       "      <td>7.779147e-06</td>\n",
       "      <td>0.111989</td>\n",
       "      <td>0.102612</td>\n",
       "      <td>-0.310623</td>\n",
       "      <td>-0.310045</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>-0.315912</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1.209636</td>\n",
       "      <td>1.209641</td>\n",
       "      <td>1.277193e-03</td>\n",
       "      <td>1.631223e-06</td>\n",
       "      <td>1.211802</td>\n",
       "      <td>1.207451</td>\n",
       "      <td>1.570106</td>\n",
       "      <td>1.569283</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>...</td>\n",
       "      <td>3.206211e-04</td>\n",
       "      <td>-0.483713</td>\n",
       "      <td>-0.544714</td>\n",
       "      <td>-0.261968</td>\n",
       "      <td>-0.262121</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.254034</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1.275497</td>\n",
       "      <td>1.275506</td>\n",
       "      <td>1.132051e-03</td>\n",
       "      <td>1.281539e-06</td>\n",
       "      <td>1.277409</td>\n",
       "      <td>1.273552</td>\n",
       "      <td>1.309699</td>\n",
       "      <td>1.307986</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>4.457948e-04</td>\n",
       "      <td>-1.469743</td>\n",
       "      <td>-1.541668</td>\n",
       "      <td>-0.464185</td>\n",
       "      <td>-0.465212</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.458360</td>\n",
       "      <td>-0.466069</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>1.330267</td>\n",
       "      <td>1.330254</td>\n",
       "      <td>1.724134e-03</td>\n",
       "      <td>2.972636e-06</td>\n",
       "      <td>1.333225</td>\n",
       "      <td>1.327490</td>\n",
       "      <td>1.249047</td>\n",
       "      <td>1.248574</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>5.118136e-05</td>\n",
       "      <td>-1.308643</td>\n",
       "      <td>-1.333015</td>\n",
       "      <td>-0.871323</td>\n",
       "      <td>-0.871197</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.854433</td>\n",
       "      <td>-0.887707</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1.423788</td>\n",
       "      <td>1.423785</td>\n",
       "      <td>2.175577e-03</td>\n",
       "      <td>4.733135e-06</td>\n",
       "      <td>1.427498</td>\n",
       "      <td>1.420093</td>\n",
       "      <td>1.420525</td>\n",
       "      <td>1.421412</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794349e-06</td>\n",
       "      <td>-1.472972</td>\n",
       "      <td>-1.480365</td>\n",
       "      <td>-0.969690</td>\n",
       "      <td>-0.969348</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.958872</td>\n",
       "      <td>-0.982568</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1.553779</td>\n",
       "      <td>1.553791</td>\n",
       "      <td>2.200005e-03</td>\n",
       "      <td>4.840023e-06</td>\n",
       "      <td>1.557504</td>\n",
       "      <td>1.549872</td>\n",
       "      <td>1.611609</td>\n",
       "      <td>1.611565</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>...</td>\n",
       "      <td>9.986774e-06</td>\n",
       "      <td>-1.911166</td>\n",
       "      <td>-1.921928</td>\n",
       "      <td>-0.562736</td>\n",
       "      <td>-0.564757</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.544822</td>\n",
       "      <td>-0.574649</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1.662960</td>\n",
       "      <td>1.662957</td>\n",
       "      <td>1.789449e-03</td>\n",
       "      <td>3.202128e-06</td>\n",
       "      <td>1.666014</td>\n",
       "      <td>1.659910</td>\n",
       "      <td>1.938579</td>\n",
       "      <td>1.939092</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>2.292732e-04</td>\n",
       "      <td>-1.436665</td>\n",
       "      <td>-1.488236</td>\n",
       "      <td>0.180951</td>\n",
       "      <td>0.179967</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.204275</td>\n",
       "      <td>0.160553</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>1.737962</td>\n",
       "      <td>1.737956</td>\n",
       "      <td>1.051290e-03</td>\n",
       "      <td>1.105212e-06</td>\n",
       "      <td>1.739764</td>\n",
       "      <td>1.736182</td>\n",
       "      <td>2.204967</td>\n",
       "      <td>2.205099</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>8.325307e-05</td>\n",
       "      <td>-1.055108</td>\n",
       "      <td>-1.086157</td>\n",
       "      <td>0.364172</td>\n",
       "      <td>0.365600</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.367588</td>\n",
       "      <td>0.356907</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>1.793783</td>\n",
       "      <td>1.793786</td>\n",
       "      <td>9.975390e-04</td>\n",
       "      <td>9.950840e-07</td>\n",
       "      <td>1.795477</td>\n",
       "      <td>1.792079</td>\n",
       "      <td>2.258426</td>\n",
       "      <td>2.259073</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>7.517051e-05</td>\n",
       "      <td>-1.300207</td>\n",
       "      <td>-1.329688</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>-0.013855</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1.838715</td>\n",
       "      <td>1.838708</td>\n",
       "      <td>8.029230e-04</td>\n",
       "      <td>6.446853e-07</td>\n",
       "      <td>1.840095</td>\n",
       "      <td>1.837360</td>\n",
       "      <td>2.161900</td>\n",
       "      <td>2.161674</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>1.247046e-05</td>\n",
       "      <td>-1.522531</td>\n",
       "      <td>-1.534581</td>\n",
       "      <td>-0.006622</td>\n",
       "      <td>-0.007690</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>-0.017275</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     P-JUS-CKGL__mean  P-JUS-CKGL__median  P-JUS-CKGL__standard_deviation  \\\n",
       "1           -0.896085           -0.896085                    1.110223e-16   \n",
       "16          -0.885541           -0.885543                    4.143325e-04   \n",
       "31          -0.868763           -0.868768                    4.445877e-04   \n",
       "46          -0.836679           -0.836674                    5.562732e-04   \n",
       "61          -0.801743           -0.801716                    1.205338e-03   \n",
       "76          -0.765230           -0.765237                    7.603757e-04   \n",
       "91          -0.746186           -0.746187                    5.716091e-06   \n",
       "106         -0.758909           -0.758903                    7.603757e-04   \n",
       "121         -0.797280           -0.797303                    1.201091e-03   \n",
       "136         -0.829212           -0.829215                    1.834467e-04   \n",
       "151         -0.835533           -0.835535                    3.466206e-04   \n",
       "166         -0.851983           -0.851944                    5.955725e-04   \n",
       "181         -0.893347           -0.893315                    4.664509e-04   \n",
       "196         -0.937856           -0.937892                    9.663119e-04   \n",
       "211         -0.981027           -0.981055                    9.391328e-04   \n",
       "226         -1.018379           -1.018377                    5.307954e-04   \n",
       "241         -1.044323           -1.044321                    3.421960e-04   \n",
       "256         -1.065768           -1.065767                    4.366846e-04   \n",
       "271         -1.089416           -1.089376                    1.581517e-04   \n",
       "286         -1.071482           -1.071485                    5.315125e-04   \n",
       "301         -1.012325           -1.012367                    1.496597e-03   \n",
       "316         -0.913340           -0.913340                    2.615726e-03   \n",
       "331         -0.769518           -0.769541                    2.681835e-03   \n",
       "346         -0.608848           -0.608877                    3.124832e-03   \n",
       "361         -0.424740           -0.424736                    3.511812e-03   \n",
       "376         -0.239197           -0.239157                    3.704126e-03   \n",
       "391         -0.058151           -0.058132                    3.397337e-03   \n",
       "406          0.107354            0.107330                    2.871520e-03   \n",
       "421          0.243088            0.243078                    2.487305e-03   \n",
       "436          0.357812            0.357807                    2.097821e-03   \n",
       "451          0.467897            0.467908                    2.308165e-03   \n",
       "466          0.570375            0.570382                    1.705359e-03   \n",
       "481          0.658499            0.658499                    1.307863e-03   \n",
       "496          0.733684            0.733685                    1.601146e-03   \n",
       "511          0.815210            0.815179                    2.054365e-03   \n",
       "526          0.926897            0.926902                    2.329813e-03   \n",
       "541          1.030682            1.030702                    1.702092e-03   \n",
       "556          1.106428            1.106427                    9.076284e-04   \n",
       "571          1.156549            1.156552                    7.791263e-04   \n",
       "586          1.209636            1.209641                    1.277193e-03   \n",
       "601          1.275497            1.275506                    1.132051e-03   \n",
       "616          1.330267            1.330254                    1.724134e-03   \n",
       "631          1.423788            1.423785                    2.175577e-03   \n",
       "646          1.553779            1.553791                    2.200005e-03   \n",
       "661          1.662960            1.662957                    1.789449e-03   \n",
       "676          1.737962            1.737956                    1.051290e-03   \n",
       "691          1.793783            1.793786                    9.975390e-04   \n",
       "706          1.838715            1.838708                    8.029230e-04   \n",
       "\n",
       "     P-JUS-CKGL__variance  P-JUS-CKGL__maximum  P-JUS-CKGL__minimum  \\\n",
       "1            1.232595e-32            -0.896085            -0.896085   \n",
       "16           1.716714e-07            -0.884834            -0.886245   \n",
       "31           1.976582e-07            -0.867995            -0.869513   \n",
       "46           3.094399e-07            -0.835740            -0.837635   \n",
       "61           1.452840e-06            -0.799741            -0.803843   \n",
       "76           5.781712e-07            -0.763923            -0.766513   \n",
       "91           3.267369e-11            -0.746174            -0.746193   \n",
       "106          5.781712e-07            -0.757626            -0.760216   \n",
       "121          1.442619e-06            -0.795198            -0.799284   \n",
       "136          3.365270e-08            -0.828895            -0.829520   \n",
       "151          1.201459e-07            -0.834934            -0.836120   \n",
       "166          3.547066e-07            -0.851043            -0.853069   \n",
       "181          2.175765e-07            -0.892615            -0.894195   \n",
       "196          9.337587e-07            -0.936142            -0.939432   \n",
       "211          8.819705e-07            -0.979375            -0.982579   \n",
       "226          2.817437e-07            -1.017479            -1.019288   \n",
       "241          1.170981e-07            -1.043745            -1.044910   \n",
       "256          1.906935e-07            -1.065026            -1.066514   \n",
       "271          2.501195e-08            -1.089231            -1.089755   \n",
       "286          2.825056e-07            -1.070570            -1.072381   \n",
       "301          2.239802e-06            -1.009695            -1.014791   \n",
       "316          6.842024e-06            -0.908885            -0.917796   \n",
       "331          7.192241e-06            -0.764907            -0.774043   \n",
       "346          9.764577e-06            -0.603472            -0.614121   \n",
       "361          1.233283e-05            -0.418765            -0.430729   \n",
       "376          1.372055e-05            -0.232977            -0.245356   \n",
       "391          1.154190e-05            -0.052400            -0.063974   \n",
       "406          8.245627e-06             0.112301             0.102285   \n",
       "421          6.186684e-06             0.247346             0.238872   \n",
       "436          4.400855e-06             0.361553             0.354245   \n",
       "451          5.327625e-06             0.471808             0.463945   \n",
       "466          2.908251e-06             0.573100             0.567464   \n",
       "481          1.710506e-06             0.660727             0.656272   \n",
       "496          2.563668e-06             0.736417             0.730952   \n",
       "511          4.220414e-06             0.818768             0.811770   \n",
       "526          5.428027e-06             0.930854             0.922926   \n",
       "541          2.897117e-06             1.033543             1.027745   \n",
       "556          8.237892e-07             1.107978             1.104877   \n",
       "571          6.070377e-07             1.157872             1.155218   \n",
       "586          1.631223e-06             1.211802             1.207451   \n",
       "601          1.281539e-06             1.277409             1.273552   \n",
       "616          2.972636e-06             1.333225             1.327490   \n",
       "631          4.733135e-06             1.427498             1.420093   \n",
       "646          4.840023e-06             1.557504             1.549872   \n",
       "661          3.202128e-06             1.666014             1.659910   \n",
       "676          1.105212e-06             1.739764             1.736182   \n",
       "691          9.950840e-07             1.795477             1.792079   \n",
       "706          6.446853e-07             1.840095             1.837360   \n",
       "\n",
       "     P-MON-CKP__mean  P-MON-CKP__median  P-MON-CKP__standard_deviation  \\\n",
       "1          -0.408539          -0.395597                       0.021751   \n",
       "16         -0.855952          -0.857024                       0.006558   \n",
       "31         -0.709083          -0.710023                       0.002611   \n",
       "46         -0.521733          -0.520007                       0.003964   \n",
       "61         -0.558425          -0.559009                       0.004024   \n",
       "76         -0.423002          -0.423446                       0.003582   \n",
       "91         -0.493687          -0.487595                       0.010399   \n",
       "106        -0.910650          -0.910537                       0.005583   \n",
       "121        -1.055357          -1.055936                       0.007972   \n",
       "136        -1.150281          -1.149910                       0.003850   \n",
       "151        -1.077207          -1.076342                       0.001791   \n",
       "166        -1.086723          -1.088956                       0.003791   \n",
       "181        -1.102501          -1.099582                       0.005137   \n",
       "196        -0.837143          -0.834964                       0.007090   \n",
       "211        -0.772451          -0.775370                       0.005137   \n",
       "226        -0.915784          -0.916282                       0.012720   \n",
       "241        -1.062139          -1.061006                       0.004236   \n",
       "256        -1.131287          -1.131107                       0.002418   \n",
       "271        -0.999753          -0.998929                       0.005023   \n",
       "286        -0.845140          -0.846769                       0.003186   \n",
       "301        -0.702382          -0.703707                       0.003250   \n",
       "316        -0.434518          -0.432359                       0.008720   \n",
       "331        -0.015984          -0.014808                       0.010595   \n",
       "346         0.190968           0.191222                       0.001164   \n",
       "361         0.030866           0.033963                       0.004298   \n",
       "376        -0.020182          -0.017157                       0.009451   \n",
       "391        -0.153477          -0.153516                       0.002261   \n",
       "406        -0.332198          -0.333275                       0.010678   \n",
       "421        -0.362195          -0.362015                       0.003586   \n",
       "436        -0.267283          -0.267474                       0.001715   \n",
       "451         0.054919           0.058752                       0.010546   \n",
       "466         0.246168           0.243163                       0.007804   \n",
       "481         0.155922           0.153727                       0.004605   \n",
       "496         0.122556           0.123396                       0.004210   \n",
       "511         0.154691           0.155149                       0.003355   \n",
       "526         0.080867           0.076908                       0.007254   \n",
       "541         0.277770           0.277653                       0.005693   \n",
       "556         0.813368           0.816529                       0.020132   \n",
       "571         1.352103           1.355183                       0.016452   \n",
       "586         1.570106           1.569283                       0.007926   \n",
       "601         1.309699           1.307986                       0.003347   \n",
       "616         1.249047           1.248574                       0.004121   \n",
       "631         1.420525           1.421412                       0.002776   \n",
       "646         1.611609           1.611565                       0.008736   \n",
       "661         1.938579           1.939092                       0.008336   \n",
       "676         2.204967           2.205099                       0.002436   \n",
       "691         2.258426           2.259073                       0.002799   \n",
       "706         2.161900           2.161674                       0.002535   \n",
       "\n",
       "     P-MON-CKP__variance  ...  T-JUS-CKP__variance  T-JUS-CKP__maximum  \\\n",
       "1               0.000473  ...         3.049081e-02            0.767983   \n",
       "16              0.000043  ...         3.247339e-06            0.273917   \n",
       "31              0.000007  ...         3.817121e-04            0.721989   \n",
       "46              0.000016  ...         2.849335e-04            1.494487   \n",
       "61              0.000016  ...         5.486716e-05            1.902829   \n",
       "76              0.000013  ...         3.971649e-05            1.618730   \n",
       "91              0.000108  ...         2.112374e-06            1.368050   \n",
       "106             0.000031  ...         1.597691e-04            1.836049   \n",
       "121             0.000064  ...         3.309602e-07            2.089596   \n",
       "136             0.000015  ...         1.276392e-04            1.787406   \n",
       "151             0.000003  ...         2.151957e-06            1.280243   \n",
       "166             0.000014  ...         4.149155e-05            0.837235   \n",
       "181             0.000026  ...         1.303727e-04            0.701847   \n",
       "196             0.000050  ...         5.828250e-05            0.630651   \n",
       "211             0.000026  ...         4.071327e-05            0.053466   \n",
       "226             0.000162  ...         2.635530e-05           -0.247815   \n",
       "241             0.000018  ...         2.465352e-05           -0.202698   \n",
       "256             0.000006  ...         3.761583e-06           -0.295640   \n",
       "271             0.000025  ...         1.262321e-06           -0.018979   \n",
       "286             0.000010  ...         1.328838e-05            0.289282   \n",
       "301             0.000011  ...         1.937870e-04           -0.102637   \n",
       "316             0.000076  ...         4.793619e-05           -0.428964   \n",
       "331             0.000112  ...         4.439177e-04            0.227317   \n",
       "346             0.000001  ...         3.897524e-06            0.781957   \n",
       "361             0.000018  ...         6.685696e-07            0.743225   \n",
       "376             0.000089  ...         2.834618e-04            0.385279   \n",
       "391             0.000005  ...         1.015864e-04           -0.023156   \n",
       "406             0.000114  ...         2.631931e-06           -0.426951   \n",
       "421             0.000013  ...         4.116301e-05           -0.745610   \n",
       "436             0.000003  ...         8.132204e-05           -0.449085   \n",
       "451             0.000111  ...         2.247334e-05           -0.129309   \n",
       "466             0.000061  ...         1.881468e-05           -0.436661   \n",
       "481             0.000021  ...         6.101201e-05           -0.575593   \n",
       "496             0.000018  ...         1.491621e-04           -0.729702   \n",
       "511             0.000011  ...         3.076763e-06           -0.871302   \n",
       "526             0.000053  ...         3.420847e-05           -0.809170   \n",
       "541             0.000032  ...         7.895604e-05           -0.522345   \n",
       "556             0.000405  ...         3.992722e-05            0.023121   \n",
       "571             0.000271  ...         7.779147e-06            0.111989   \n",
       "586             0.000063  ...         3.206211e-04           -0.483713   \n",
       "601             0.000011  ...         4.457948e-04           -1.469743   \n",
       "616             0.000017  ...         5.118136e-05           -1.308643   \n",
       "631             0.000008  ...         4.794349e-06           -1.472972   \n",
       "646             0.000076  ...         9.986774e-06           -1.911166   \n",
       "661             0.000069  ...         2.292732e-04           -1.436665   \n",
       "676             0.000006  ...         8.325307e-05           -1.055108   \n",
       "691             0.000008  ...         7.517051e-05           -1.300207   \n",
       "706             0.000006  ...         1.247046e-05           -1.522531   \n",
       "\n",
       "     T-JUS-CKP__minimum  T-TPT__mean  T-TPT__median  \\\n",
       "1              0.238172     2.186833       2.229633   \n",
       "16             0.266663     2.610011       2.607677   \n",
       "31             0.658324     2.306829       2.304432   \n",
       "46             1.434600     1.812628       1.813480   \n",
       "61             1.877594     1.830739       1.830503   \n",
       "76             1.596020     1.937297       1.936576   \n",
       "91             1.363227     1.220057       1.219773   \n",
       "106            1.794148     0.627857       0.628625   \n",
       "121            2.087472     0.790488       0.793082   \n",
       "136            1.748915     0.762861       0.762410   \n",
       "151            1.275180     0.740999       0.739469   \n",
       "166            0.816426     0.739752       0.739483   \n",
       "181            0.666193     0.226614       0.227037   \n",
       "196            0.604648    -0.634607      -0.632705   \n",
       "211            0.029361    -1.375509      -1.375390   \n",
       "226           -0.263782    -1.464603      -1.465015   \n",
       "241           -0.219851    -0.999022      -0.999514   \n",
       "256           -0.301745    -0.650649      -0.650850   \n",
       "271           -0.022792    -0.397007      -0.398081   \n",
       "286            0.278025    -0.063052      -0.063597   \n",
       "301           -0.149570    -0.118322      -0.117261   \n",
       "316           -0.450813    -0.810568      -0.810573   \n",
       "331            0.155983    -1.304925      -1.305326   \n",
       "346            0.774528    -1.127066      -1.126516   \n",
       "361            0.740496    -1.043801      -1.043648   \n",
       "376            0.331081    -1.091977      -1.091512   \n",
       "391           -0.057507    -0.728332      -0.729156   \n",
       "406           -0.433128    -0.208204      -0.208703   \n",
       "421           -0.767449    -0.322088      -0.322077   \n",
       "436           -0.479782    -0.680501      -0.681042   \n",
       "451           -0.145459    -0.664913      -0.663788   \n",
       "466           -0.450388    -0.485267      -0.485797   \n",
       "481           -0.602210    -0.180291      -0.180210   \n",
       "496           -0.768214    -0.062947      -0.061236   \n",
       "511           -0.877115    -0.187390      -0.189870   \n",
       "526           -0.826575    -0.124756      -0.126518   \n",
       "541           -0.552698    -0.014022      -0.012465   \n",
       "556            0.001612    -0.150794      -0.150328   \n",
       "571            0.102612    -0.310623      -0.310045   \n",
       "586           -0.544714    -0.261968      -0.262121   \n",
       "601           -1.541668    -0.464185      -0.465212   \n",
       "616           -1.333015    -0.871323      -0.871197   \n",
       "631           -1.480365    -0.969690      -0.969348   \n",
       "646           -1.921928    -0.562736      -0.564757   \n",
       "661           -1.488236     0.180951       0.179967   \n",
       "676           -1.086157     0.364172       0.365600   \n",
       "691           -1.329688    -0.000327       0.000921   \n",
       "706           -1.534581    -0.006622      -0.007690   \n",
       "\n",
       "     T-TPT__standard_deviation  T-TPT__variance  T-TPT__maximum  \\\n",
       "1                     0.121185         0.014686        2.327431   \n",
       "16                    0.006759         0.000046        2.624352   \n",
       "31                    0.005371         0.000029        2.318819   \n",
       "46                    0.004221         0.000018        1.819434   \n",
       "61                    0.005360         0.000029        1.839244   \n",
       "76                    0.007788         0.000061        1.951509   \n",
       "91                    0.014843         0.000220        1.246684   \n",
       "106                   0.006461         0.000042        0.637082   \n",
       "121                   0.004851         0.000024        0.794868   \n",
       "136                   0.004113         0.000017        0.769842   \n",
       "151                   0.006742         0.000045        0.755097   \n",
       "166                   0.004661         0.000022        0.748663   \n",
       "181                   0.009167         0.000084        0.241934   \n",
       "196                   0.012870         0.000166       -0.616396   \n",
       "211                   0.010402         0.000108       -1.358906   \n",
       "226                   0.003156         0.000010       -1.459621   \n",
       "241                   0.007605         0.000058       -0.985550   \n",
       "256                   0.010009         0.000100       -0.633616   \n",
       "271                   0.005212         0.000027       -0.386172   \n",
       "286                   0.001309         0.000002       -0.059616   \n",
       "301                   0.006162         0.000038       -0.109211   \n",
       "316                   0.016686         0.000278       -0.782074   \n",
       "331                   0.007718         0.000060       -1.290411   \n",
       "346                   0.010166         0.000103       -1.110858   \n",
       "361                   0.003193         0.000010       -1.038752   \n",
       "376                   0.008368         0.000070       -1.078731   \n",
       "391                   0.010706         0.000115       -0.708725   \n",
       "406                   0.004408         0.000019       -0.200212   \n",
       "421                   0.006023         0.000036       -0.311542   \n",
       "436                   0.002608         0.000007       -0.674406   \n",
       "451                   0.004430         0.000020       -0.659638   \n",
       "466                   0.004177         0.000017       -0.476882   \n",
       "481                   0.004227         0.000018       -0.172766   \n",
       "496                   0.003350         0.000011       -0.059830   \n",
       "511                   0.005574         0.000031       -0.175071   \n",
       "526                   0.004227         0.000018       -0.115794   \n",
       "541                   0.003392         0.000012       -0.011140   \n",
       "556                   0.001572         0.000002       -0.149181   \n",
       "571                   0.002610         0.000007       -0.307413   \n",
       "586                   0.004994         0.000025       -0.254034   \n",
       "601                   0.002000         0.000004       -0.458360   \n",
       "616                   0.009720         0.000094       -0.854433   \n",
       "631                   0.007859         0.000062       -0.958872   \n",
       "646                   0.008694         0.000076       -0.544822   \n",
       "661                   0.013480         0.000182        0.204275   \n",
       "676                   0.003429         0.000012        0.367588   \n",
       "691                   0.007146         0.000051        0.009708   \n",
       "706                   0.007487         0.000056        0.008061   \n",
       "\n",
       "     T-TPT__minimum  class  \n",
       "1          1.965559    0.0  \n",
       "16         2.601740    0.0  \n",
       "31         2.301961    0.0  \n",
       "46         1.804589    0.0  \n",
       "61         1.821407    0.0  \n",
       "76         1.925094    0.0  \n",
       "91         1.195443    0.0  \n",
       "106        0.615918    0.0  \n",
       "121        0.779080    0.0  \n",
       "136        0.756557    0.0  \n",
       "151        0.732013    0.0  \n",
       "166        0.733096    0.0  \n",
       "181        0.210301    0.0  \n",
       "196       -0.659814    0.0  \n",
       "211       -1.393686    0.0  \n",
       "226       -1.468815    0.0  \n",
       "241       -1.010521    0.0  \n",
       "256       -0.667374    0.0  \n",
       "271       -0.404672    0.0  \n",
       "286       -0.064312    0.0  \n",
       "301       -0.130364  107.0  \n",
       "316       -0.839371  107.0  \n",
       "331       -1.317910  107.0  \n",
       "346       -1.144902  107.0  \n",
       "361       -1.049401  107.0  \n",
       "376       -1.107039  107.0  \n",
       "391       -0.745165  107.0  \n",
       "406       -0.214436  107.0  \n",
       "421       -0.332753  107.0  \n",
       "436       -0.683935  107.0  \n",
       "451       -0.674788  107.0  \n",
       "466       -0.492520  107.0  \n",
       "481       -0.187264  107.0  \n",
       "496       -0.070435  107.0  \n",
       "511       -0.192926  107.0  \n",
       "526       -0.128951  107.0  \n",
       "541       -0.022906  107.0  \n",
       "556       -0.154897  107.0  \n",
       "571       -0.315912  107.0  \n",
       "586       -0.271153  107.0  \n",
       "601       -0.466069  107.0  \n",
       "616       -0.887707  107.0  \n",
       "631       -0.982568  107.0  \n",
       "646       -0.574649  107.0  \n",
       "661        0.160553  107.0  \n",
       "676        0.356907  107.0  \n",
       "691       -0.013855    7.0  \n",
       "706       -0.017275    7.0  \n",
       "\n",
       "[48 rows x 43 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = pd.concat([X, y], axis=1)\n",
    "# model_data = processed_data[processed_data['class'] != 7]\n",
    "model_data = processed_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class_label(instance_n, class_column):\n",
    "    class_mappings = {\n",
    "        1: {0: 0, 101: 1, 1: 1},\n",
    "        2: {0: 0, 102: 1, 2: 1},\n",
    "        3: {0: 0, 103: 1, 3: 1},\n",
    "        4: {0: 0, 104: 1, 4: 1},\n",
    "        5: {0: 0, 105: 1, 5: 1},\n",
    "        6: {0: 0, 106: 1, 6: 1},\n",
    "        7: {0: 0, 107: 1, 7: 1},\n",
    "        8: {0: 0, 108: 1, 8: 1}\n",
    "    }\n",
    "    \n",
    "    if instance_n in class_mappings:\n",
    "        return class_column.replace(class_mappings[instance_n])\n",
    "    else:\n",
    "        print(\"instance_number is out of range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 28, 1.0: 28})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming 'class' is your target variable\n",
    "X = model_data.drop(columns=['class'])  # Features\n",
    "y = model_data['class']  # Target\n",
    "y = update_class_label(instance_n, y)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combine resampled features and target\n",
    "processed_data_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "# Display the new class distribution\n",
    "print(\"Resampled class distribution:\", Counter(processed_data_resampled['class']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = processed_data_resampled.drop(columns=['class'])  # Features\n",
    "y = processed_data_resampled['class']  # Target\n",
    "# Perform the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42, stratify=y_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the given model using the provided test data and returns key performance metrics.\n",
    "    \"\"\"\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    auc_roc = roc_auc_score(y_test, y_prob)\n",
    "    auc_prc = average_precision_score(y_test, y_prob)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Compile all metrics into a dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"auc_roc\": auc_roc,\n",
    "        \"auc_prc\": auc_prc,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P-JUS-CKGL__mean',\n",
       " 'P-JUS-CKGL__median',\n",
       " 'P-JUS-CKGL__standard_deviation',\n",
       " 'P-JUS-CKGL__variance',\n",
       " 'P-JUS-CKGL__maximum',\n",
       " 'P-JUS-CKGL__minimum',\n",
       " 'P-MON-CKP__mean',\n",
       " 'P-MON-CKP__median',\n",
       " 'P-MON-CKP__standard_deviation',\n",
       " 'P-MON-CKP__variance',\n",
       " 'P-MON-CKP__maximum',\n",
       " 'P-MON-CKP__minimum',\n",
       " 'P-PDG__mean',\n",
       " 'P-PDG__median',\n",
       " 'P-PDG__standard_deviation',\n",
       " 'P-PDG__variance',\n",
       " 'P-PDG__maximum',\n",
       " 'P-PDG__minimum',\n",
       " 'P-TPT__mean',\n",
       " 'P-TPT__median',\n",
       " 'P-TPT__standard_deviation',\n",
       " 'P-TPT__variance',\n",
       " 'P-TPT__maximum',\n",
       " 'P-TPT__minimum',\n",
       " 'QGL__mean',\n",
       " 'QGL__median',\n",
       " 'QGL__standard_deviation',\n",
       " 'QGL__variance',\n",
       " 'QGL__maximum',\n",
       " 'QGL__minimum',\n",
       " 'T-JUS-CKP__mean',\n",
       " 'T-JUS-CKP__median',\n",
       " 'T-JUS-CKP__standard_deviation',\n",
       " 'T-JUS-CKP__variance',\n",
       " 'T-JUS-CKP__maximum',\n",
       " 'T-JUS-CKP__minimum',\n",
       " 'T-TPT__mean',\n",
       " 'T-TPT__median',\n",
       " 'T-TPT__standard_deviation',\n",
       " 'T-TPT__variance',\n",
       " 'T-TPT__maximum',\n",
       " 'T-TPT__minimum']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "AUC-ROC: 1.0\n",
      "AUC-PRC: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "         1.0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "Model saved as 'best_random_forest_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from grid search\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Test model\n",
    "metrics_rf, y_pred_rf = evaluate_model(best_model_rf, X_test, y_test)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", metrics_rf['accuracy'])\n",
    "print(\"Precision:\", metrics_rf['precision'])\n",
    "print(\"Recall:\", metrics_rf['recall'])\n",
    "print(\"F1 Score:\", metrics_rf['f1_score'])\n",
    "print(\"AUC-ROC:\", metrics_rf['auc_roc'])\n",
    "print(\"AUC-PRC:\", metrics_rf['auc_prc'])\n",
    "print(\"\\nClassification Report:\\n\", metrics_rf['classification_report'])\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model_rf, f'./predictionModel/{instance_n}/best_random_forest_model.pkl')\n",
    "print(\"Model saved as 'best_random_forest_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_or_update_metrics(model_name, metrics, index, filename):\n",
    "    \"\"\"\n",
    "    Save or update the metrics dictionary to a CSV file with a specified index.\n",
    "    \"\"\"\n",
    "    # Prepare the metrics dictionary with the proper format\n",
    "    metrics_formatted = {\n",
    "        f'{model_name}_accuracy': metrics['accuracy'],\n",
    "        f'{model_name}_precision': metrics['precision'],\n",
    "        f'{model_name}_recall': metrics['recall'],\n",
    "        f'{model_name}_f1': metrics['f1_score'],\n",
    "        f'{model_name}_auc_roc': metrics['auc_roc'],\n",
    "        f'{model_name}_auc_prc': metrics['auc_prc']\n",
    "    }\n",
    "\n",
    "    # Convert metrics dictionary to DataFrame with the specified index\n",
    "    metrics_df = pd.DataFrame([metrics_formatted], index=[index])\n",
    "\n",
    "    # Get the current working directory\n",
    "    current_directory = os.getcwd()\n",
    "    \n",
    "    filepath = os.path.join(current_directory, filename)\n",
    "\n",
    "    # Check if the CSV file already exists\n",
    "    if os.path.exists(filepath):\n",
    "        # Read existing CSV file\n",
    "        existing_df = pd.read_csv(filepath, index_col=0)\n",
    "        if index in existing_df.index:\n",
    "            # Update existing columns or add new columns for the same index\n",
    "            for col in metrics_df.columns:\n",
    "                existing_df.loc[index, col] = metrics_df.loc[index, col]\n",
    "            updated_df = existing_df\n",
    "        else:\n",
    "            # Append new metrics if the index doesn't exist\n",
    "            updated_df = pd.concat([existing_df, metrics_df])\n",
    "    else:\n",
    "        # Create new DataFrame if file does not exist\n",
    "        updated_df = metrics_df\n",
    "\n",
    "    # Save DataFrame to CSV\n",
    "    updated_df.to_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or update the metrics to CSV\n",
    "save_or_update_metrics('rf',metrics_rf, instance_n, 'model_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "def plot_metrics(y_test, y_prob):\n",
    "    \"\"\"\n",
    "    Plots ROC Curve and Precision-Recall Curve.\n",
    "    \"\"\"\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    prc_auc = auc(recall, precision)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (area = {prc_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Test model\n",
    "metrics_rf, y_pred_rf = evaluate_model(best_model_rf, X_test, y_test)\n",
    "\n",
    "# Plot the ROC and Precision-Recall curves\n",
    "plot_metrics(y_test, best_model_rf.predict_proba(X_test)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Loop through the first 10 trees in the random forest\n",
    "for i, tree in enumerate(best_model_rf.estimators_[:10]):\n",
    "    if i == 9:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plot_tree(tree, filled=True, feature_names=X_test.columns, class_names=['normal', 'faulty'], rounded=True)\n",
    "        plt.title(f\"Decision Tree from Random Forest\", fontsize=16)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Confusion Matrix for Random Forest Classifier', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['Normal', 'Faulty'], fontsize=12)  # Adjust labels according to your classes\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['Normal', 'Faulty'], fontsize=12)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model_rf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP values\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ainbahar/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:07:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'xgb__colsample_bytree': 0.8, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100, 'xgb__subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [100, 200],\n",
    "    'xgb__max_depth': [3, 6, 9],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb__subsample': [0.8, 1.0],\n",
    "    'xgb__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create a pipeline with XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n",
    "])\n",
    "# Initialize model\n",
    "xg_boost = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_xgb.fit(X_train,y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(\"Best Parameters:\", best_params_xgb)\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = best_model_xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=3, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=100, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=3, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=100, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('xgb',\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric='mlogloss',\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=3, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=100, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "AUC-ROC: 1.0\n",
      "AUC-PRC: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "         1.0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "Model saved as 'best_xgboost_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from grid search\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Test model\n",
    "metrics_xgb, y_pred_xgb = evaluate_model(best_model_xgb, X_test, y_test)\n",
    "\n",
    "# Print the metrics\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", metrics_xgb['accuracy'])\n",
    "print(\"Precision:\", metrics_xgb['precision'])\n",
    "print(\"Recall:\", metrics_xgb['recall'])\n",
    "print(\"F1 Score:\", metrics_xgb['f1_score'])\n",
    "print(\"AUC-ROC:\", metrics_xgb['auc_roc'])\n",
    "print(\"AUC-PRC:\", metrics_xgb['auc_prc'])\n",
    "print(\"\\nClassification Report:\\n\", metrics_xgb['classification_report'])\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "\n",
    "joblib.dump(best_model_rf, f'./predictionModel/{instance_n}/best_xgboost_model.pkl')\n",
    "print(\"Model saved as 'best_xgboost_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or update the metrics to CSV\n",
    "save_or_update_metrics('xgb',metrics_xgb, instance_n, 'model_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (12, 42)\n",
      "Testing data size: (36, 42)\n"
     ]
    }
   ],
   "source": [
    "X_lof = processed_data.drop(columns=['class'])\n",
    "y_lof = update_class_label(instance_n, processed_data['class'])\n",
    "\n",
    "# Separate the data based on the class\n",
    "X_class_0 = X_lof[y_lof == 0]\n",
    "y_class_0 = y_lof[y_lof == 0]\n",
    "\n",
    "X_class_1 = X_lof[y_lof == 1]\n",
    "y_class_1 = y_lof[y_lof == 1]\n",
    "\n",
    "# Split class 0 data into training and testing sets (60% train, 40% test)\n",
    "X_class_0_train, X_class_0_test, y_class_0_train, y_class_0_test = train_test_split(\n",
    "    X_class_0, y_class_0, test_size=0.40, random_state=42\n",
    ")\n",
    "\n",
    "# 60% of train dataset\n",
    "X_lof_train = X_class_0_train\n",
    "y_lof_train = y_class_0\n",
    "\n",
    "# 40% of test dataset\n",
    "X_lof_test = pd.concat([X_class_0_test, X_class_1])\n",
    "y_lof_test = pd.concat([y_class_0_test, y_class_1])\n",
    "\n",
    "# Print sizes of the resulting splits for verification\n",
    "print(f\"Training data size: {X_lof_train.shape}\")\n",
    "print(f\"Testing data size: {X_lof_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'contamination': 0.05, 'n_neighbors': 5, 'novelty': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 20, 30],  # Explore different numbers of neighbors\n",
    "    'contamination': [0.05, 0.1, 0.15] , # Explore different contamination levels\n",
    "    'novelty': [True]\n",
    "}\n",
    "\n",
    "# Initialize the LOF model\n",
    "lof = LocalOutlierFactor()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lof, param_grid=param_grid, \n",
    "                           scoring='f1',  # Choose an appropriate scoring metric\n",
    "                           cv=3)  # 3-fold cross-validation\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X_lof_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_lof = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'contamination': 0.05, 'n_neighbors': 5, 'novelty': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 20, 30],  # Explore different numbers of neighbors\n",
    "    'contamination': [0.05, 0.1, 0.15] , # Explore different contamination levels\n",
    "    'novelty': [True]\n",
    "}\n",
    "\n",
    "# Initialize the LOF model\n",
    "lof = LocalOutlierFactor()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lof, param_grid=param_grid, \n",
    "                           scoring='f1',  # Choose an appropriate scoring metric\n",
    "                           cv=3)  # 3-fold cross-validation\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X_lof_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_lof = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 5  3]\n",
      " [ 5 23]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.62      0.56         8\n",
      "         1.0       0.88      0.82      0.85        28\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.69      0.72      0.70        36\n",
      "weighted avg       0.80      0.78      0.79        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict outliers on the test data\n",
    "lof_test_predictions = best_lof.predict(X_lof_test)\n",
    "lof_test_predictions = np.where(lof_test_predictions == 1, 0, 1)\n",
    "\n",
    "# Convert predictions to DataFrame if needed\n",
    "X_lof_test['LOF_Score'] = lof_test_predictions\n",
    "\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_lof_test, lof_test_predictions)\n",
    "class_report = classification_report(y_lof_test, lof_test_predictions)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7777777777777778, 'precision': 0.8846153846153846, 'recall': 0.8214285714285714, 'f1_score': 0.8518518518518519, 'auc_roc': 0.7232142857142858, 'auc_prc': 0.8655372405372406}\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_lof_test, lof_test_predictions)\n",
    "precision = precision_score(y_lof_test, lof_test_predictions)\n",
    "recall = recall_score(y_lof_test, lof_test_predictions)\n",
    "f1 = f1_score(y_lof_test, lof_test_predictions)\n",
    "\n",
    "# Initialize AUC metrics\n",
    "roc_auc = None\n",
    "prc_auc = None\n",
    "\n",
    "if lof_test_predictions is not None:\n",
    "    roc_auc = roc_auc_score(y_lof_test, lof_test_predictions)\n",
    "    prc_auc = average_precision_score(y_lof_test, lof_test_predictions)\n",
    "\n",
    "# Create a dictionary of metrics\n",
    "metrics_lof = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'auc_roc': roc_auc,\n",
    "    'auc_prc': prc_auc\n",
    "}\n",
    "\n",
    "print(metrics_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or update the metrics to CSV\n",
    "save_or_update_metrics('lof',metrics_lof, instance_n, 'model_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_instance_n(instance_n):\n",
    "    files_labeled= [path for label, path in real_instances if label == instance_n]\n",
    "\n",
    "    # Read the CSV files into DataFrames\n",
    "    dataframes = [pd.read_csv(file) for file in files_labeled]\n",
    "\n",
    "    # assign names to these DataFrames for easy access\n",
    "    df_dict= {file.stem: pd.read_csv(file) for file in files_labeled}\n",
    "    \n",
    "    print(f\"Number of instances set to: {toi.index[instance_n]}\")\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances set to: 7 - Scaling in PCK\n"
     ]
    }
   ],
   "source": [
    "df_dict = load_real_instance_n(instance_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_list_1 = ['WELL-00001_20140124093303', 'WELL-00006_20170731180930','WELL-00006_20170731220432', 'WELL-00006_20180617200257']\n",
    "instance_list_2 = ['WELL-00010_20171218190131' ,'WELL-00002_20131104014101','WELL-00009_20170313160804']\n",
    "instance_list_5 = ['WELL-00015_20170620040530','WELL-00017_20140319031616','WELL-00017_20140314135248']\n",
    "instance_list_6 = ['WELL-00002_20140325170304','WELL-00002_20140301151700', 'WELL-00002_20140212170333']\n",
    "instance_list_7 = ['WELL-00018_20180611021218','WELL-00001_20170226140146','WELL-00006_20180617181315', 'WELL-00018_20190403023307', 'WELL-00006_20180620155728']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(df, columns) :  \n",
    "# Subset the DataFrame to only include the specified columns\n",
    "    print(df.columns)\n",
    "    subset_df = df[columns]\n",
    "\n",
    "    # Calculate the percentage of null values for each column in the subset\n",
    "    null_percentages = subset_df.isnull().mean() * 100\n",
    "\n",
    "    # List the columns with more than 18% null values\n",
    "    columns_with_high_nulls = null_percentages[null_percentages > 18].index.tolist()\n",
    "\n",
    "    # Drop the columns with high null values from the subset DataFrame\n",
    "    modified_df = subset_df.drop(columns=columns_with_high_nulls)\n",
    "\n",
    "    # Forward fill na values in the 'class' column\n",
    "    if 'class' in modified_df.columns:\n",
    "        modified_df['class'] = modified_df['class'].fillna(method='ffill')\n",
    "        \n",
    "    \n",
    "    # modified_df = modified_df[modified_df['class'].notnull()]\n",
    "\n",
    "    # # replace 'class' with 107.0 as 7.0\n",
    "    # modified_df['class'] = modified_df['class'].replace(107.0, 7.0)\n",
    "\n",
    "    # Smooth the DataFrame using a moving average \n",
    "    window_size = 1800\n",
    "    smoothed_df = modified_df.copy()\n",
    "    sensor_columns = modified_df.columns.difference(['class'])\n",
    "    smoothed_df[sensor_columns] = modified_df[sensor_columns].rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "    return(modified_df, smoothed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_outlier(df, columns):\n",
    "    from scipy.stats import zscore\n",
    "    \n",
    "\n",
    "    # Calculate Z-scores for each column\n",
    "    df_zscores = df[columns].apply(zscore)\n",
    "\n",
    "    # Set a threshold for Z-scores to identify outliers\n",
    "    threshold = 3\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = (np.abs(df_zscores) > threshold).any(axis=1)\n",
    "\n",
    "    # Replace outliers with rolling average\n",
    "    window_size = 3  # Set window size for rolling average\n",
    "    z_score_df = df.copy()\n",
    "\n",
    "    for col in columns:\n",
    "        rolling_avg = df[col].rolling(window=window_size, min_periods=1).mean()\n",
    "        z_score_df.loc[outliers, col] = rolling_avg[outliers]\n",
    "\n",
    "\n",
    "    return(z_score_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "     # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    auc_roc = roc_auc_score(y, y_pred)\n",
    "    auc_prc = average_precision_score(y, y_pred)\n",
    "\n",
    "    # Compile all metrics into a dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"auc_roc\": auc_roc,\n",
    "        \"auc_prc\": auc_prc\n",
    "    }\n",
    "    \n",
    "    return y_pred, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_list_var(instance_n):\n",
    "    # Mapping of instance_n to the corresponding instance list\n",
    "    instance_lists = {\n",
    "        1: instance_list_1,\n",
    "        2: instance_list_2,\n",
    "        5: instance_list_5,\n",
    "        6: instance_list_6,\n",
    "        7: instance_list_7\n",
    "    }\n",
    "    \n",
    "    # Check if instance_n is valid\n",
    "    if instance_n not in instance_lists:\n",
    "        print(f\"Error: instance_n {instance_n} is not valid\")\n",
    "        return None\n",
    "\n",
    "    # Get the corresponding instance list\n",
    "    instance_list = instance_lists[instance_n]\n",
    "\n",
    "    return (instance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELL-00001_20170226140146\n",
      "Index(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'P-JUS-CKGL',\n",
      "       'T-JUS-CKGL', 'QGL', 'class'],\n",
      "      dtype='object')\n",
      "                     P-PDG         P-TPT     T-TPT     P-MON-CKP  T-JUS-CKP  \\\n",
      "timestamp                                                                     \n",
      "2017-02-26 14:01:46    0.0  1.331329e+07  118.1245  5.333321e+06  74.215710   \n",
      "2017-02-26 14:01:47    0.0  1.331333e+07  118.1245  5.333460e+06  74.215945   \n",
      "2017-02-26 14:01:48    0.0  1.331337e+07  118.1245  5.333599e+06  74.216177   \n",
      "2017-02-26 14:01:49    0.0  1.331342e+07  118.1245  5.333737e+06  74.216410   \n",
      "2017-02-26 14:01:50    0.0  1.331346e+07  118.1245  5.333876e+06  74.216644   \n",
      "\n",
      "                       P-JUS-CKGL  QGL  class  id  \n",
      "timestamp                                          \n",
      "2017-02-26 14:01:46  3.382723e+06  0.0    0.0   1  \n",
      "2017-02-26 14:01:47  3.382724e+06  0.0    0.0   1  \n",
      "2017-02-26 14:01:48  3.382724e+06  0.0    0.0   1  \n",
      "2017-02-26 14:01:49  3.382724e+06  0.0    0.0   1  \n",
      "2017-02-26 14:01:50  3.382724e+06  0.0    0.0   1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [00:00<00:00, 154.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELL-00006_20180617181315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'P-JUS-CKGL',\n",
      "       'T-JUS-CKGL', 'QGL', 'class'],\n",
      "      dtype='object')\n",
      "                            P-PDG         P-TPT      T-TPT     P-MON-CKP  \\\n",
      "timestamp                                                                  \n",
      "2018-06-17 18:13:15 -1.180116e+42  2.081367e+07  117.84760  1.013681e+07   \n",
      "2018-06-17 18:13:16 -1.180116e+42  2.081364e+07  117.84755  1.013675e+07   \n",
      "2018-06-17 18:13:17 -1.180116e+42  2.081361e+07  117.84750  1.013669e+07   \n",
      "2018-06-17 18:13:18 -1.180116e+42  2.081358e+07  117.84745  1.013662e+07   \n",
      "2018-06-17 18:13:19 -1.180116e+42  2.081356e+07  117.84740  1.013656e+07   \n",
      "\n",
      "                     T-JUS-CKP  P-JUS-CKGL  QGL  class  id  \n",
      "timestamp                                                   \n",
      "2018-06-17 18:13:15  70.839520   4040100.0  0.0    0.0   1  \n",
      "2018-06-17 18:13:16  70.839510   4040100.0  0.0    0.0   1  \n",
      "2018-06-17 18:13:17  70.839503   4040100.0  0.0    0.0   1  \n",
      "2018-06-17 18:13:18  70.839495   4040100.0  0.0    0.0   1  \n",
      "2018-06-17 18:13:19  70.839486   4040100.2  0.0    0.0   1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [00:00<00:00, 61.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELL-00018_20190403023307\n",
      "Index(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'P-JUS-CKGL',\n",
      "       'T-JUS-CKGL', 'QGL', 'class'],\n",
      "      dtype='object')\n",
      "                     P-PDG       P-TPT       T-TPT     P-MON-CKP  T-JUS-CKP  \\\n",
      "timestamp                                                                     \n",
      "2019-04-03 02:33:07    0.0  8431399.00  109.856400  1.367659e+06   73.72916   \n",
      "2019-04-03 02:33:08    0.0  8431364.00  109.856100  1.368448e+06   73.72916   \n",
      "2019-04-03 02:33:09    0.0  8431329.00  109.855833  1.369236e+06   73.72916   \n",
      "2019-04-03 02:33:10    0.0  8431293.75  109.855575  1.369631e+06   73.72916   \n",
      "2019-04-03 02:33:11    0.0  8431258.60  109.855320  1.369867e+06   73.72916   \n",
      "\n",
      "                     P-JUS-CKGL  QGL  class  id  \n",
      "timestamp                                        \n",
      "2019-04-03 02:33:07   8810764.0  0.0    0.0   1  \n",
      "2019-04-03 02:33:08   8810764.0  0.0    0.0   1  \n",
      "2019-04-03 02:33:09   8810764.0  0.0    0.0   1  \n",
      "2019-04-03 02:33:10   8810764.0  0.0    0.0   1  \n",
      "2019-04-03 02:33:11   8810764.0  0.0    0.0   1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [00:00<00:00, 238.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELL-00006_20180620155728\n",
      "Index(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'P-JUS-CKGL',\n",
      "       'T-JUS-CKGL', 'QGL', 'class'],\n",
      "      dtype='object')\n",
      "                            P-PDG         P-TPT       T-TPT     P-MON-CKP  \\\n",
      "timestamp                                                                   \n",
      "2018-06-20 16:29:03 -1.180116e+42  2.108536e+07  117.632425  1.185283e+07   \n",
      "2018-06-20 16:29:04 -1.180116e+42  2.108539e+07  117.632493  1.185298e+07   \n",
      "2018-06-20 16:29:05 -1.180116e+42  2.108541e+07  117.632561  1.185313e+07   \n",
      "2018-06-20 16:29:06 -1.180116e+42  2.108544e+07  117.632629  1.185328e+07   \n",
      "2018-06-20 16:29:07 -1.180116e+42  2.108547e+07  117.632696  1.185344e+07   \n",
      "\n",
      "                     T-JUS-CKP    P-JUS-CKGL  QGL  class  id  \n",
      "timestamp                                                     \n",
      "2018-06-20 16:29:03  63.292364  1.459317e+06  0.0    0.0   1  \n",
      "2018-06-20 16:29:04  63.294436  1.459340e+06  0.0    0.0   1  \n",
      "2018-06-20 16:29:05  63.296509  1.459362e+06  0.0    0.0   1  \n",
      "2018-06-20 16:29:06  63.298584  1.459385e+06  0.0    0.0   1  \n",
      "2018-06-20 16:29:07  63.300659  1.459408e+06  0.0    0.0   1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [00:00<00:00, 100.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "    accuracy  precision    recall  f1_score   auc_roc   auc_prc\n",
      "0  0.914634   0.915034  0.914634  0.914698  0.915072  0.894446\n",
      "1  0.924528   0.938570  0.924528  0.926146  0.943662  0.962796\n",
      "2  0.760000   0.852903  0.760000  0.760000  0.806452  0.612903\n",
      "3  0.595238   0.908009  0.595238  0.662304  0.770270  0.945302\n",
      "XGBoost \n",
      "    accuracy  precision    recall  f1_score   auc_roc   auc_prc\n",
      "0  0.597561   0.638374  0.597561  0.582397  0.612440  0.611619\n",
      "1  0.566038   0.812485  0.566038  0.548112  0.676056  0.786075\n",
      "2  0.740000   0.845625  0.740000  0.738647  0.790323  0.593750\n",
      "3  0.571429   0.906832  0.571429  0.640306  0.756757  0.942085\n",
      "Local Outlier Factor \n",
      "    accuracy  precision    recall  f1_score   auc_roc   auc_prc\n",
      "0  0.524390   0.538462  0.795455  0.642202  0.502990  0.538078\n",
      "1  0.669811   0.669811  1.000000  0.802260  0.500000  0.669811\n",
      "2  0.660000   0.527778  1.000000  0.690909  0.725806  0.527778\n",
      "3  0.880952   0.880952  1.000000  0.936709  0.500000  0.880952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf_metrics_list = []\n",
    "xgb_metrics_list = []\n",
    "lof_metrics_list = []\n",
    "\n",
    "train_df = get_instance_list_var(instance_n)[0]\n",
    "list = get_instance_list_var(instance_n)\n",
    "\n",
    "for instances in df_dict:\n",
    "    val_df= df_dict[instances]\n",
    "    # print(instances)\n",
    "    # print(val_df.head())\n",
    "    if instances != train_df and instances in list :\n",
    "        print(instances)\n",
    "        # print(val_df.head())\n",
    "        # print(val_df['timestamp'].head())\n",
    "        val_df['timestamp'] = pd.to_datetime(val_df['timestamp'])\n",
    "        val_df = val_df.set_index('timestamp').sort_index()    \n",
    "        # print(val_df.head())\n",
    "\n",
    "        clean_vdf, smooth_vdf = handle_missing_data(val_df, val_df.columns)\n",
    "        smooth_vdf = smooth_vdf[smooth_vdf['class'].notnull()]\n",
    "        # print(smooth_vdf.head())\n",
    "        z_score_vdf = z_score_outlier(smooth_vdf, cols_to_check)\n",
    "        resample_vdf = time_windowing(smooth_vdf)\n",
    "        # print(resample_vdf.head())\n",
    "\n",
    "\n",
    "\n",
    "        print(resample_vdf.head())\n",
    "        if 'class' in resample_vdf.columns:\n",
    "            X_vdf = resample_vdf[cols_to_check]\n",
    "            y_vdf = resample_vdf['class']\n",
    "            window = resample_vdf['id']\n",
    "\n",
    "            scale_vdf = scaler.fit_transform(X_vdf)\n",
    "            vdf = pd.DataFrame(scale_vdf, index = X_vdf.index, columns = X_vdf.columns)\n",
    "            vdf['class'] = y_vdf.values\n",
    "            vdf['id'] = window.values\n",
    "            vdf = vdf.reset_index()\n",
    "            vdf.rename(columns={'timestamp':'time'}, inplace = True)\n",
    "\n",
    "            X_val = extract_and_impute_features(vdf)\n",
    "            y_val = vdf.groupby('id')['class'].first()\n",
    "            y_val = update_class_label(instance_n, y_val)\n",
    "\n",
    "            y_pred_rf, rf_metrics = validation_metrics(best_model_rf, X_val, y_val)\n",
    "            y_pred_xgb, xgb_metrics = validation_metrics(best_model_xgb, X_val, y_val)\n",
    "\n",
    "            y_pred_lof = best_lof.predict(X_val)\n",
    "            y_pred_lof = np.where(y_pred_lof == 1, 0, 1)\n",
    "\n",
    "            accuracy = accuracy_score(y_val, y_pred_lof)\n",
    "            precision = precision_score(y_val, y_pred_lof)\n",
    "            recall = recall_score(y_val, y_pred_lof)\n",
    "            f1 = f1_score(y_val, y_pred_lof)\n",
    "\n",
    "            # Initialize AUC metrics\n",
    "            roc_auc = None\n",
    "            prc_auc = None\n",
    "\n",
    "            if lof_test_predictions is not None:\n",
    "                roc_auc = roc_auc_score(y_val, y_pred_lof)\n",
    "                prc_auc = average_precision_score(y_val, y_pred_lof)\n",
    "\n",
    "\n",
    "            # Create a dictionary of metrics\n",
    "            lof_metrics = {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'auc_roc': roc_auc,\n",
    "                'auc_prc': prc_auc\n",
    "            }\n",
    "\n",
    "            rf_metrics_list.append(rf_metrics)\n",
    "            xgb_metrics_list.append(xgb_metrics)\n",
    "            lof_metrics_list.append(lof_metrics)\n",
    "\n",
    "\n",
    "# Convert list of metrics to a DataFrame\n",
    "\n",
    "rf_metrics_df = pd.DataFrame(rf_metrics_list)\n",
    "print(\"Random Forest \\n\" , rf_metrics_df)\n",
    "\n",
    "xgb_metrics_df = pd.DataFrame(xgb_metrics_list)\n",
    "print(\"XGBoost \\n\" , xgb_metrics_df)\n",
    "\n",
    "lof_metrics_df = pd.DataFrame(lof_metrics_list)\n",
    "print(\"Local Outlier Factor \\n\" , lof_metrics_df)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model  accuracy  precision    recall  f1_score   auc_roc   auc_prc\n",
      "0    rf  0.798600   0.903629  0.798600  0.815787  0.858864  0.853862\n",
      "1   xgb  0.618757   0.800829  0.618757  0.627366  0.708894  0.733382\n",
      "2   lof  0.683788   0.654251  0.948864  0.768020  0.557199  0.654155\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean for each metric in each model's DataFrame\n",
    "rf_mean_metrics = rf_metrics_df.mean().to_frame().T\n",
    "xgb_mean_metrics = xgb_metrics_df.mean().to_frame().T\n",
    "lof_mean_metrics = lof_metrics_df.mean().to_frame().T\n",
    "\n",
    "# Add a 'model' column to each DataFrame to identify the model\n",
    "rf_mean_metrics['model'] = 'rf'\n",
    "xgb_mean_metrics['model'] = 'xgb'\n",
    "lof_mean_metrics['model'] = 'lof'\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "mean_metrics_df = pd.concat([rf_mean_metrics, xgb_mean_metrics, lof_mean_metrics], ignore_index=True)\n",
    "\n",
    "# Reorder the columns so 'model' is the first column\n",
    "mean_metrics_df = mean_metrics_df[['model', 'accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'auc_prc']]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(mean_metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model  accuracy  precision    recall  f1_score   auc_roc   auc_prc\n",
      "0    rf  0.155100   0.036255  0.155100  0.127321  0.083558  0.163234\n",
      "1   xgb  0.081993   0.115139  0.081993  0.083376  0.080215  0.163968\n",
      "2   lof  0.147244   0.164356  0.102273  0.130900  0.112414  0.164446\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard deviation for each metric in each model's DataFrame\n",
    "rf_std_metrics = rf_metrics_df.std().to_frame().T\n",
    "xgb_std_metrics = xgb_metrics_df.std().to_frame().T\n",
    "lof_std_metrics = lof_metrics_df.std().to_frame().T\n",
    "\n",
    "# Add a 'model' column to each DataFrame to identify the model\n",
    "rf_std_metrics['model'] = 'rf'\n",
    "xgb_std_metrics['model'] = 'xgb'\n",
    "lof_std_metrics['model'] = 'lof'\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "std_metrics_df = pd.concat([rf_std_metrics, xgb_std_metrics, lof_std_metrics], ignore_index=True)\n",
    "\n",
    "# Reorder the columns so 'model' is the first column\n",
    "std_metrics_df = std_metrics_df[['model', 'accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'auc_prc']]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(std_metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
